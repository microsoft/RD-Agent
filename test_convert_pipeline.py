"""
Dataset SFT Conversion Pipeline (Phase 2: SFT Conversion).
Workflow: Load migrated dataset â†’ Schema Analysis â†’ Intelligent Routing â†’ Convert to Alpaca format

Prerequisites: Run test_pipeline.py first to migrate dataset to ./datasets/raw/
"""

import json
import os
from pathlib import Path

from rdagent.components.data import convert_to_sft

# Configuration
DATASETS_ROOT = Path("./datasets/raw")
OUTPUT_DIR = Path("./datasets/sft")
TASK_DESCRIPTION = "æ•°å­¦æ¨ç†æ•°æ®é›†"  # éœ€è¦ä¸ test_pipeline.py ä¿æŒä¸€è‡´

print("=" * 70)
print("SFT è½¬æ¢æµç¨‹ (Phase 2: æ•°æ®è½¬æ¢ä¸æ¸…æ´—)")
print("=" * 70)
print(f"æ•°æ®é›†æ ¹ç›®å½•: {DATASETS_ROOT}")
print(f"è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
print(f"ä»»åŠ¡æè¿°: {TASK_DESCRIPTION}")
print("=" * 70)


def find_latest_dataset(datasets_root: Path) -> Path:
    """æŸ¥æ‰¾æœ€æ–°è¿ç§»çš„æ•°æ®é›†ç›®å½•"""
    if not datasets_root.exists():
        raise FileNotFoundError(f"æ•°æ®é›†æ ¹ç›®å½•ä¸å­˜åœ¨: {datasets_root}")

    # è·å–æ‰€æœ‰å­ç›®å½•
    subdirs = [d for d in datasets_root.iterdir() if d.is_dir()]

    if not subdirs:
        raise FileNotFoundError(f"æœªæ‰¾åˆ°ä»»ä½•æ•°æ®é›†: {datasets_root}")

    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè¿”å›æœ€æ–°çš„
    latest_dataset = max(subdirs, key=lambda d: d.stat().st_mtime)
    return latest_dataset


def test_sft_conversion():
    """æµ‹è¯• SFT è½¬æ¢æµç¨‹ï¼ˆæ™ºèƒ½åˆ†æµï¼‰"""

    # Step 1: æŸ¥æ‰¾æœ€æ–°æ•°æ®é›†
    print("\n[Step 1/3] æŸ¥æ‰¾è¿ç§»åçš„æ•°æ®é›†...")

    try:
        dataset_path = find_latest_dataset(DATASETS_ROOT)
        print(f"âœ… æ‰¾åˆ°æ•°æ®é›†: {dataset_path.name}")
        print(f"   è·¯å¾„: {dataset_path}")
        print(f"   ä¿®æ”¹æ—¶é—´: {dataset_path.stat().st_mtime}")
    except Exception as e:
        print(f"âŒ æœªæ‰¾åˆ°æ•°æ®é›†: {e}")
        print(f"\næç¤º: è¯·å…ˆè¿è¡Œ test_pipeline.py ä¸‹è½½å¹¶è¿ç§»æ•°æ®é›†")
        return False

    # Step 2: å‡†å¤‡è¾“å‡ºè·¯å¾„
    print("\n[Step 2/3] å‡†å¤‡è¾“å‡ºè·¯å¾„...")

    output_file = OUTPUT_DIR / f"{dataset_path.name}_alpaca.json"
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    print(f"âœ… è¾“å‡ºè·¯å¾„å‡†å¤‡å®Œæˆ")
    print(f"   è¾“å‡ºæ–‡ä»¶: {output_file}")

    # Clean checkpoint before conversion
    checkpoint_file = Path("sft_checkpoint.json")
    if checkpoint_file.exists():
        checkpoint_file.unlink()
        print(f"   ğŸ§¹ æ¸…ç† checkpoint: {checkpoint_file}")

    # Step 3: SFT è½¬æ¢ï¼ˆæ™ºèƒ½åˆ†æµï¼‰
    print("\n[Step 3/3] SFT è½¬æ¢ï¼ˆæ™ºèƒ½åˆ†æµç³»ç»Ÿï¼‰...")
    print("=" * 70)
    print("æ™ºèƒ½åˆ†æµè¯´æ˜:")
    print("  - è½»é‡è·¯å¾„ (Light Path): æ ‡å‡† Q&A æ•°æ® â†’ ç®€å•è½¬æ¢ + å»é‡ + å¹¶è¡Œè´¨é‡è¯„åˆ†")
    print("  - é‡åº¦è·¯å¾„ (Heavy Path): æ··ä¹±æ•°æ® â†’ å»é‡ + ç›´æ¥å¹¶è¡Œ LLM è½¬æ¢")
    print("  - ç³»ç»Ÿè‡ªåŠ¨æ ¹æ®æ•°æ®è´¨é‡é€‰æ‹©è·¯å¾„")
    print("=" * 70)

    try:
        result = convert_to_sft(
            input_path=str(dataset_path),
            output_file=str(output_file),
            task_description=TASK_DESCRIPTION,
        )

        # éªŒè¯ç»“æœ
        print("\nâœ… è½¬æ¢å®Œæˆ!")
        print("=" * 70)
        print("è½¬æ¢ç»Ÿè®¡:")
        print(f"  å¤„ç†è·¯å¾„: {result.get('processing_path', 'unknown').upper()}")
        print(f"  æˆåŠŸçŠ¶æ€: {result['success']}")
        print(f"  è¾“å…¥æ ·æœ¬: {result['stats'].get('total_rows', 0)}")
        print(f"  è¾“å‡ºæ ·æœ¬: {result['stats'].get('successful_rows', 0)}")
        print(f"  è´¨é‡åˆ†æ•°: {result['stats'].get('quality_score', 0):.2f}")
        print("=" * 70)

        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
        if output_file.exists():
            with open(output_file, "r", encoding="utf-8") as f:
                output_data = json.load(f)

            print(f"\nğŸ“„ è¾“å‡ºæ–‡ä»¶éªŒè¯:")
            print(f"  æ–‡ä»¶è·¯å¾„: {output_file}")
            print(f"  æ ·æœ¬æ€»æ•°: {len(output_data)}")
            print(f"  æ–‡ä»¶å¤§å°: {output_file.stat().st_size / 1024 / 1024:.2f}MB")
            print(f"  æ ¼å¼éªŒè¯: {'âœ“' if all('instruction' in s and 'output' in s for s in output_data) else 'âœ—'}")

            # æ˜¾ç¤ºç¤ºä¾‹
            if output_data:
                print(f"\nğŸ“ ç¤ºä¾‹æ ·æœ¬ (å‰ 3 ä¸ª):")
                for i, sample in enumerate(output_data[:3]):
                    print(f"\n  æ ·æœ¬ {i+1}:")
                    print(f"    instruction: {sample['instruction'][:80]}...")
                    if sample.get("input"):
                        print(f"    input: {sample['input'][:60]}...")
                    print(f"    output: {sample['output'][:80]}...")
                    if "metadata" in sample:
                        print(f"    metadata: {sample['metadata']}")

            # æ•°æ®è´¨é‡ç»Ÿè®¡
            if output_data:
                avg_instruction_len = sum(len(s["instruction"]) for s in output_data) / len(output_data)
                avg_output_len = sum(len(s["output"]) for s in output_data) / len(output_data)
                has_metadata = sum(1 for s in output_data if "metadata" in s)

                print(f"\nğŸ“Š æ•°æ®è´¨é‡ç»Ÿè®¡:")
                print(f"  å¹³å‡ instruction é•¿åº¦: {avg_instruction_len:.0f} å­—ç¬¦")
                print(f"  å¹³å‡ output é•¿åº¦: {avg_output_len:.0f} å­—ç¬¦")
                print(f"  åŒ…å« metadata: {has_metadata}/{len(output_data)} æ ·æœ¬")

        return result["success"]

    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return False


def main():
    """è¿è¡Œå®Œæ•´çš„ SFT è½¬æ¢æµç¨‹"""

    success = test_sft_conversion()

    # æ€»ç»“
    print("\n" + "=" * 70)
    if success:
        print("âœ… SFT è½¬æ¢æµç¨‹å®Œæˆ!")
        print("=" * 70)
        print("ä¸‹ä¸€æ­¥å»ºè®®:")
        print("  1. æ£€æŸ¥è¾“å‡ºæ–‡ä»¶è´¨é‡")
        print("  2. ä½¿ç”¨è¾“å‡ºæ–‡ä»¶è¿›è¡Œ LoRA/SFT è®­ç»ƒ")
        print(f"  3. è¾“å‡ºæ–‡ä»¶ä½ç½®: {OUTPUT_DIR}")
    else:
        print("âŒ SFT è½¬æ¢å¤±è´¥!")
        print("=" * 70)
        print("è¯·æ£€æŸ¥:")
        print("  1. æ˜¯å¦å·²è¿è¡Œ test_pipeline.py è¿ç§»æ•°æ®é›†?")
        print("  2. æ•°æ®é›†æ ¼å¼æ˜¯å¦æ­£ç¡®?")
        print("  3. LLM API æ˜¯å¦é…ç½®æ­£ç¡®?")
    print("=" * 70)


if __name__ == "__main__":
    main()
