"""
Dataset preparation script (Phase 1: Data Collection).
Workflow: Search â†’ Download â†’ Inspect â†’ LLM Filter â†’ Migrate to ./datasets/raw/

For SFT conversion, use sft_converter.py (Phase 2).
"""

import shutil
from pathlib import Path

from rdagent.components.data import (
    DatasetInspector,
    DatasetManager,
    DatasetSearchAgent,
)

# Configuration
TASK_DESCRIPTION = "æ•°å­¦æ¨ç†æ•°æ®é›†"
TEMP_STAGING_DIR = "/tmp/dataset_staging"
FINAL_STORAGE_DIR = "./datasets"
MAX_CANDIDATES = 5

print("=" * 70)
print("æ•°æ®é›†å‡†å¤‡æµç¨‹ (Phase 1: æ•°æ®é‡‡é›†ä¸è¿ç§»)")
print("=" * 70)
print(f"ä»»åŠ¡: {TASK_DESCRIPTION}")
print(f"ä¸´æ—¶ç›®å½•: {TEMP_STAGING_DIR}")
print(f"æœ€ç»ˆå­˜å‚¨: {FINAL_STORAGE_DIR}/raw/")
print("=" * 70)

# Step 1: Search and Download to temporary directory
print("\n[Step 1/4] æœç´¢å¹¶ä¸‹è½½æ•°æ®é›†...")
agent = DatasetSearchAgent()

try:
    search_result = agent.search_and_download(
        task_description=TASK_DESCRIPTION,
        out_dir=TEMP_STAGING_DIR,
        max_candidates=MAX_CANDIDATES,
    )

    print(f"âœ… ä¸‹è½½å®Œæˆ!")
    print(f"  æ•°æ®é›†ID: {search_result['dataset_id']}")
    print(f"  ä¸´æ—¶è·¯å¾„: {search_result['dataset_path']}")
    print(f"  ç½®ä¿¡åº¦: {search_result['confidence']:.2f}")
    print(f"  ç†ç”±: {search_result['reason']}")

except Exception as e:
    print(f"âŒ æœç´¢ä¸‹è½½å¤±è´¥: {e}")
    exit(1)

# Step 2: Inspect dataset structure
print("\n[Step 2/4] æ£€æŸ¥æ•°æ®é›†ç»“æ„...")
inspector = DatasetInspector()

try:
    inspect_result = inspector.inspect(search_result["dataset_path"], sample_size=10)

    print(f"âœ… æ£€æŸ¥å®Œæˆ!")
    print(f"  å¯åŠ è½½: {inspect_result['loadable']}")
    print(f"  æ ·æœ¬æ•°: {inspect_result['total_samples']}")
    print(f"  åˆ—å: {inspect_result['columns']}")

    if inspect_result["issues"]:
        print(f"  âš ï¸  å‘ç°é—®é¢˜:")
        for issue in inspect_result["issues"]:
            print(f"    - {issue}")

except Exception as e:
    print(f"âŒ æ•°æ®é›†æ£€æŸ¥å¤±è´¥: {e}")
    exit(1)

# Step 3: LLM analyzes which files are useful for SFT
print("\n[Step 3/4] LLMåˆ†ææ–‡ä»¶ï¼ˆè¯†åˆ«åƒåœ¾æ–‡ä»¶ï¼‰...")

try:
    file_analysis = inspector.analyze_files_for_sft(
        dataset_path=search_result["dataset_path"],
        task_description=TASK_DESCRIPTION,
    )

    print(f"âœ… æ–‡ä»¶åˆ†æå®Œæˆ!")
    print(f"  æœ‰ç”¨æ–‡ä»¶: {len(file_analysis['useful_files'])}")
    print(f"  åƒåœ¾æ–‡ä»¶: {len(file_analysis['junk_files'])}")
    print(f"  åŸå§‹å¤§å°: {file_analysis['total_size_mb']:.2f}MB")
    print(f"  æ¸…ç†å: {file_analysis['size_after_cleanup_mb']:.2f}MB")
    print(f"  èŠ‚çœç©ºé—´: {file_analysis['space_saved_mb']:.2f}MB")

    if file_analysis["junk_files"]:
        print(f"\n  ğŸ—‘ï¸  å°†åˆ é™¤çš„åƒåœ¾æ–‡ä»¶:")
        for junk_file in file_analysis["junk_files"][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"    - {junk_file}")
        if len(file_analysis["junk_files"]) > 10:
            print(f"    ... è¿˜æœ‰ {len(file_analysis['junk_files']) - 10} ä¸ªæ–‡ä»¶")

except Exception as e:
    print(f"âŒ æ–‡ä»¶åˆ†æå¤±è´¥: {e}")
    print(f"  å°†ä½¿ç”¨è§„åˆ™è¿‡æ»¤ä½œä¸ºåå¤‡æ–¹æ¡ˆ")
    # å¦‚æœLLMå¤±è´¥ï¼Œanalyze_files_for_sftä¼šè‡ªåŠ¨fallbackåˆ°è§„åˆ™è¿‡æ»¤
    import traceback

    traceback.print_exc()

# Step 4: Selective migration to ./datasets/raw/
print("\n[Step 4/4] è¿ç§»åˆ°æ°¸ä¹…å­˜å‚¨ï¼ˆåªå¤åˆ¶æœ‰ç”¨æ–‡ä»¶ï¼‰...")
manager = DatasetManager(permanent_root=FINAL_STORAGE_DIR)

try:
    migration_result = manager.migrate_dataset_selective(
        source_path=search_result["dataset_path"],
        dataset_id=search_result["dataset_id"],
        file_analysis=file_analysis,
    )

    print(f"âœ… è¿ç§»å®Œæˆ!")
    print(f"  ç›®æ ‡è·¯å¾„: {migration_result['target_path']}")
    print(f"  å¤åˆ¶æ–‡ä»¶æ•°: {len(migration_result['copied_files'])}")
    print(f"  è·³è¿‡æ–‡ä»¶æ•°: {len(migration_result['skipped_files'])}")
    print(f"  èŠ‚çœç©ºé—´: {migration_result['space_saved_mb']:.2f}MB")

except Exception as e:
    print(f"âŒ è¿ç§»å¤±è´¥: {e}")
    import traceback

    traceback.print_exc()
    exit(1)

# Final summary
print("\n" + "=" * 70)
print("âœ… æ•°æ®é›†å‡†å¤‡å®Œæˆï¼å·²è¿ç§»è‡³æ°¸ä¹…å­˜å‚¨")
