{"cells":[{"metadata":{"_cell_guid":"5cb12f78-e5a9-47d9-bcfd-ca322744c2ce","_uuid":"2903ba531fb15d3943b80f28774e0d24d0377741"},"source":"This is an example notebook to demonstrate how the IoU metric works for a single image. Please note: this is not the official scoring implementation, but should work in the same manner.","cell_type":"markdown"},{"metadata":{"_cell_guid":"1b889269-1027-4261-a3e9-54f75223571b","collapsed":true,"_uuid":"3fd84142326a40f5f7ba094ce49c125d5a95837b"},"source":"%matplotlib inline\nimport numpy as np\nimport skimage.io\nimport matplotlib.pyplot as plt\nimport skimage.segmentation\n\n# Load a single image and its associated masks\nid = '0a7d30b252359a10fd298b638b90cb9ada3acced4e0c0e5a3692013f432ee4e9'\nfile = \"../input/stage1_train/{}/images/{}.png\".format(id,id)\nmasks = \"../input/stage1_train/{}/masks/*.png\".format(id)\nimage = skimage.io.imread(file)\nmasks = skimage.io.imread_collection(masks).concatenate()\nheight, width, _ = image.shape\nnum_masks = masks.shape[0]\n\n# Make a ground truth label image (pixel value is index of object label)\nlabels = np.zeros((height, width), np.uint16)\nfor index in range(0, num_masks):\n    labels[masks[index] > 0] = index + 1\n\n# Show label image\nfig = plt.figure()\nplt.imshow(image)\nplt.title(\"Original image\")\nfig = plt.figure()\nplt.imshow(labels)\nplt.title(\"Ground truth masks\")\n\n# Simulate an imperfect submission\noffset = 2 # offset pixels\ny_pred = labels[offset:, offset:]\ny_pred = np.pad(y_pred, ((0, offset), (0, offset)), mode=\"constant\")\ny_pred[y_pred == 20] = 0 # Remove one object\ny_pred, _, _ = skimage.segmentation.relabel_sequential(y_pred) # Relabel objects\n\n# Show simulated predictions\nfig = plt.figure()\nplt.imshow(y_pred)\nplt.title(\"Simulated imperfect submission\")\n\n# Compute number of objects\ntrue_objects = len(np.unique(labels))\npred_objects = len(np.unique(y_pred))\nprint(\"Number of true objects:\", true_objects)\nprint(\"Number of predicted objects:\", pred_objects)\n\n# Compute intersection between all objects\nintersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n\n# Compute areas (needed for finding the union between all objects)\narea_true = np.histogram(labels, bins = true_objects)[0]\narea_pred = np.histogram(y_pred, bins = pred_objects)[0]\narea_true = np.expand_dims(area_true, -1)\narea_pred = np.expand_dims(area_pred, 0)\n\n# Compute union\nunion = area_true + area_pred - intersection\n\n# Exclude background from the analysis\nintersection = intersection[1:,1:]\nunion = union[1:,1:]\nunion[union == 0] = 1e-9\n\n# Compute the intersection over union\niou = intersection / union\n\n# Precision helper function\ndef precision_at(threshold, iou):\n    matches = iou > threshold\n    true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n    tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n    return tp, fp, fn\n\n# Loop over IoU thresholds\nprec = []\nprint(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\nfor t in np.arange(0.5, 1.0, 0.05):\n    tp, fp, fn = precision_at(t, iou)\n    p = tp / (tp + fp + fn)\n    print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n    prec.append(p)\nprint(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))","cell_type":"code","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bc357ad2-d10c-4f5b-9f6a-55d47336779f","collapsed":true,"_uuid":"542d2b226d90fc13cc852979f529962387873420"},"source":"","cell_type":"code","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"name":"python","nbconvert_exporter":"python","version":"3.6.4","pygments_lexer":"ipython3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py"}},"nbformat_minor":1,"nbformat":4}