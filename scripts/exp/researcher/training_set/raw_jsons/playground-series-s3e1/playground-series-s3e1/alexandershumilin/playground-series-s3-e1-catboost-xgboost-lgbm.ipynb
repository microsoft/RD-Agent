{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Please upvote my notebook if You like it! :)**","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import fetch_california_housing\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-09T04:22:04.244855Z","iopub.execute_input":"2023-01-09T04:22:04.245754Z","iopub.status.idle":"2023-01-09T04:22:05.467727Z","shell.execute_reply.started":"2023-01-09T04:22:04.245649Z","shell.execute_reply":"2023-01-09T04:22:05.465516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install reverse_geocoder","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:22:05.470263Z","iopub.execute_input":"2023-01-09T04:22:05.470958Z","iopub.status.idle":"2023-01-09T04:22:19.483071Z","shell.execute_reply.started":"2023-01-09T04:22:05.470919Z","shell.execute_reply":"2023-01-09T04:22:19.481896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Downloading data**","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/playground-series-s3e1/train.csv')\ntest_df = pd.read_csv('/kaggle/input/playground-series-s3e1/test.csv')\nsubmission = pd.read_csv('/kaggle/input/playground-series-s3e1/sample_submission.csv')\ntrain_df = train_df.drop('id', axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:22:19.484555Z","iopub.execute_input":"2023-01-09T04:22:19.48509Z","iopub.status.idle":"2023-01-09T04:22:19.697971Z","shell.execute_reply.started":"2023-01-09T04:22:19.485047Z","shell.execute_reply":"2023-01-09T04:22:19.695981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extra_data = fetch_california_housing()\ntrain_data2 = pd.DataFrame(extra_data['data'])\ntrain_data2['MedHouseVal'] = extra_data['target']\ntrain_data2.columns = train_df.columns\ntrain_df['generated'] = 1\ntest_df['generated'] = 1\ntrain_data2['generated'] = 0\n# train_df = pd.concat([train_df, train_data2],axis=0).drop_duplicates()\ntrain_df = pd.concat([train_df, train_data2],axis=0, ignore_index=True)\n\ntrain_df.loc[33228,['Latitude','Longitude']] = [32.74, -117]\ntrain_df.loc[34363,['Latitude','Longitude']] = [32.71, -117]\ntrain_df.loc[20991,['Latitude','Longitude']] = [34.2, -119]\n\nprint(train_df.shape)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:22:19.700561Z","iopub.execute_input":"2023-01-09T04:22:19.700904Z","iopub.status.idle":"2023-01-09T04:22:21.33625Z","shell.execute_reply.started":"2023-01-09T04:22:19.700874Z","shell.execute_reply":"2023-01-09T04:22:21.334347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['r'] = np.sqrt(train_df['Latitude']**2 + train_df['Longitude']**2)\ntrain_df['theta'] = np.arctan2(train_df['Latitude'], train_df['Longitude'])\n\ntest_df['r'] = np.sqrt(test_df['Latitude']**2 + test_df['Longitude']**2)\ntest_df['theta'] = np.arctan2(test_df['Latitude'], test_df['Longitude'])","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:22:21.338212Z","iopub.execute_input":"2023-01-09T04:22:21.338673Z","iopub.status.idle":"2023-01-09T04:22:21.358153Z","shell.execute_reply.started":"2023-01-09T04:22:21.33862Z","shell.execute_reply":"2023-01-09T04:22:21.356503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([train_df, test_df], axis=0, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:22:21.359856Z","iopub.execute_input":"2023-01-09T04:22:21.360496Z","iopub.status.idle":"2023-01-09T04:22:21.37107Z","shell.execute_reply.started":"2023-01-09T04:22:21.360456Z","shell.execute_reply":"2023-01-09T04:22:21.369929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Encoding trick (see here: https://www.kaggle.com/competitions/playground-series-s3e1/discussion/376210)","metadata":{}},{"cell_type":"code","source":"emb_size = 20\nprecision = 1e6 \n\nlatlon = np.expand_dims(df[['Latitude', 'Longitude']].values, axis=-1) \n\nm = np.exp(np.log(precision) / emb_size) \nangle_freq = m ** np.arange(emb_size) \nangle_freq = angle_freq.reshape(1, 1, emb_size) \n\nlatlon = latlon * angle_freq \nlatlon[..., 0::2] = np.cos(latlon[..., 0::2]) \nlatlon[..., 1::2] = np.sin(latlon[..., 1::2]) \nlatlon = latlon.reshape(-1, 2 * emb_size) \n\ndf['exp_latlon1'] = [lat[0] for lat in latlon]\ndf['exp_latlon2'] = [lat[1] for lat in latlon]","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:22:21.373956Z","iopub.execute_input":"2023-01-09T04:22:21.374451Z","iopub.status.idle":"2023-01-09T04:22:21.521925Z","shell.execute_reply.started":"2023-01-09T04:22:21.374347Z","shell.execute_reply":"2023-01-09T04:22:21.520103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thanks to @dmitryuarov for feature engineering ideas with coordinates! Please, upvote his notebook: https://www.kaggle.com/code/dmitryuarov/ps-s3e1-coordinates-key-to-victory","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\ndef pca(data):\n    '''\n    input: dataframe containing Latitude(x) and Longitude(y)\n    '''\n    coordinates = data[['Latitude','Latitude']].values\n    pca_obj = PCA().fit(coordinates)\n    pca_x = pca_obj.transform(data[['Latitude', 'Longitude']].values)[:,0]\n    pca_y = pca_obj.transform(data[['Latitude', 'Longitude']].values)[:,1]\n    return pca_x, pca_y\n\n# train_df['pca_x'], train_df['pca_y'] = pca(train_df)\n# test_df['pca_x'], test_df['pca_y'] = pca(test_df)\ndf['pca_x'], df['pca_y'] = pca(df)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:22:21.524204Z","iopub.execute_input":"2023-01-09T04:22:21.524639Z","iopub.status.idle":"2023-01-09T04:22:21.684112Z","shell.execute_reply.started":"2023-01-09T04:22:21.524602Z","shell.execute_reply":"2023-01-09T04:22:21.683312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from umap import UMAP\ncoordinates = df[['Latitude', 'Longitude']].values\numap = UMAP(n_components=2, n_neighbors=50, random_state=228).fit(coordinates)\ndf['umap_lat'] = umap.transform(coordinates)[:,0]\ndf['umap_lon'] = umap.transform(coordinates)[:,1]","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:22:21.685478Z","iopub.execute_input":"2023-01-09T04:22:21.686008Z","iopub.status.idle":"2023-01-09T04:27:17.584818Z","shell.execute_reply.started":"2023-01-09T04:22:21.68597Z","shell.execute_reply":"2023-01-09T04:27:17.583884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crt_crds(df): \n    df['rot_15_x'] = (np.cos(np.radians(15)) * df['Longitude']) + \\\n                      (np.sin(np.radians(15)) * df['Latitude'])\n    \n    df['rot_15_y'] = (np.cos(np.radians(15)) * df['Latitude']) + \\\n                      (np.sin(np.radians(15)) * df['Longitude'])\n    \n    df['rot_30_x'] = (np.cos(np.radians(30)) * df['Longitude']) + \\\n                      (np.sin(np.radians(30)) * df['Latitude'])\n    \n    df['rot_30_y'] = (np.cos(np.radians(30)) * df['Latitude']) + \\\n                      (np.sin(np.radians(30)) * df['Longitude'])\n    \n    df['rot_45_x'] = (np.cos(np.radians(45)) * df['Longitude']) + \\\n                      (np.sin(np.radians(45)) * df['Latitude'])\n    return df\n\n# train_df = crt_crds(train_df)\n# test_df = crt_crds(test_df)\ndf = crt_crds(df)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:27:17.589284Z","iopub.execute_input":"2023-01-09T04:27:17.590749Z","iopub.status.idle":"2023-01-09T04:27:17.608216Z","shell.execute_reply.started":"2023-01-09T04:27:17.590711Z","shell.execute_reply":"2023-01-09T04:27:17.606503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import reverse_geocoder as rg\nfrom sklearn.preprocessing import LabelEncoder\n\ndef geocoder(df):\n    coordinates = list(zip(df['Latitude'], df['Longitude']))\n    results = rg.search(coordinates)\n    return results\n\n# results = geocoder(train_df)\n# train_df['place'] = [x['admin2'] for x in results]\n# results = geocoder(test_df)\n# test_df['place'] = [x['admin2'] for x in results]\n\nresults = geocoder(df)\ndf['place'] = [x['admin2'] for x in results]\n\nplaces = ['Los Angeles County', 'Orange County', 'Kern County',\n          'Alameda County', 'San Francisco County', 'Ventura County',\n          'Santa Clara County', 'Fresno County', 'Santa Barbara County',\n          'Contra Costa County', 'Yolo County', 'Monterey County',\n          'Riverside County', 'Napa County']\n\ndef replace(x):\n    if x in places:\n        return x\n    else:\n        return 'Other'\n    \n# train_df['place'] = train_df['place'].apply(lambda x: replace(x))\n# test_df['place'] = test_df['place'].apply(lambda x: replace(x))\n\ndf['place'] = df['place'].apply(lambda x: replace(x))\n\n# le = LabelEncoder()\n# train_df['place'] = le.fit_transform(train_df['place'])\n# test_df['place'] = le.transform(test_df['place'])\n\n# test_df = pd.get_dummies(test_df)\n# train_df = pd.get_dummies(train_df)\n\ndf = pd.get_dummies(df)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:27:17.609662Z","iopub.execute_input":"2023-01-09T04:27:17.61023Z","iopub.status.idle":"2023-01-09T04:27:19.381733Z","shell.execute_reply.started":"2023-01-09T04:27:17.610161Z","shell.execute_reply":"2023-01-09T04:27:19.379405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Distances to cities and coast points","metadata":{}},{"cell_type":"code","source":"from haversine import haversine\n\nSac = (38.576931, -121.494949)\nSF = (37.780080, -122.420160)\nSJ = (37.334789, -121.888138)\nLA = (34.052235, -118.243683)\nSD = (32.715759, -117.163818)\n\ndf['dist_Sac'] = df.apply(lambda x: haversine((x['Latitude'], x['Longitude']), Sac, unit='ft'), axis=1)\ndf['dist_SF'] = df.apply(lambda x: haversine((x['Latitude'], x['Longitude']), SF, unit='ft'), axis=1)\ndf['dist_SJ'] = df.apply(lambda x: haversine((x['Latitude'], x['Longitude']), SJ, unit='ft'), axis=1)\ndf['dist_LA'] = df.apply(lambda x: haversine((x['Latitude'], x['Longitude']), LA, unit='ft'), axis=1)\ndf['dist_SD'] = df.apply(lambda x: haversine((x['Latitude'], x['Longitude']), SD, unit='ft'), axis=1)\ndf['dist_nearest_city'] = df[['dist_Sac', 'dist_SF', 'dist_SJ', \n                              'dist_LA', 'dist_SD']].min(axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:27:19.384209Z","iopub.execute_input":"2023-01-09T04:27:19.38468Z","iopub.status.idle":"2023-01-09T04:27:26.65432Z","shell.execute_reply.started":"2023-01-09T04:27:19.384639Z","shell.execute_reply":"2023-01-09T04:27:26.652898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from shapely.geometry import LineString, Point\n\ncoast_points = LineString([(32.6644, -117.1613), (33.2064, -117.3831),\n                           (33.7772, -118.2024), (34.4634, -120.0144),\n                           (35.4273, -120.8819), (35.9284, -121.4892),\n                           (36.9827, -122.0289), (37.6114, -122.4916),\n                           (38.3556, -123.0603), (39.7926, -123.8217),\n                           (40.7997, -124.1881), (41.7558, -124.1976)])\n\ndf['dist_to_coast'] = df.apply(lambda x: Point(x['Latitude'], x['Longitude']).distance(coast_points), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:27:26.656294Z","iopub.execute_input":"2023-01-09T04:27:26.656684Z","iopub.status.idle":"2023-01-09T04:27:29.355851Z","shell.execute_reply.started":"2023-01-09T04:27:26.656654Z","shell.execute_reply":"2023-01-09T04:27:29.354493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# combine latitude and longitude\n# codes from \n# https://datascience.stackexchange.com/questions/49553/combining-latitude-longitude-position-into-single-feature\nfrom math import radians, cos, sin, asin, sqrt\n\ndef single_pt_haversine(lat, lng, degrees=True):\n    \"\"\"\n    'Single-point' Haversine: Calculates the great circle distance\n    between a point on Earth and the (0, 0) lat-long coordinate\n    \"\"\"\n    r = 6371 # Earth's radius (km). Have r = 3956 if you want miles\n\n    # Convert decimal degrees to radians\n    if degrees:\n        lat, lng = map(radians, [lat, lng])\n\n    # 'Single-point' Haversine formula\n    a = sin(lat/2)**2 + cos(lat) * sin(lng/2)**2\n    d = 2 * r * asin(sqrt(a)) \n\n    return d\n# add more metric \n# referred to this discussion\n# https://www.kaggle.com/competitions/playground-series-s3e1/discussion/376210\n\ndef manhattan(lat,lng):\n    return np.abs(lat) + np.abs(lng)\ndef euclidean(lat,lng):\n    return (lat**2 + lng**2) **0.5\n\ndef add_combine(df):      \n    df['haversine'] = [single_pt_haversine(x, y) for x, y in zip(df.Latitude, df.Longitude)]\n    df['manhattan'] = [manhattan(x,y) for x,y in zip(df.Latitude, df.Longitude)]\n    df['euclidean'] = [euclidean(x,y) for x,y in zip(df.Latitude,df.Longitude)]\n    return df\n\ndf = add_combine(df)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:27:29.357461Z","iopub.execute_input":"2023-01-09T04:27:29.357815Z","iopub.status.idle":"2023-01-09T04:27:29.675465Z","shell.execute_reply.started":"2023-01-09T04:27:29.357788Z","shell.execute_reply":"2023-01-09T04:27:29.674449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.neighbors import KNeighborsRegressor\n\n# neighbors = 15\n\n# knn = KNeighborsRegressor(n_neighbors = neighbors,\n#                             metric = 'haversine',\n#                             n_jobs = -1)\n# knn.fit(df[['Latitude','Longitude']], df.index)\n# dists, nears = knn.kneighbors(df[['Latitude', 'Longitude']], \n#                                 return_distance = True)\n\n# df[['dist1', 'dist2', 'dist3', 'dist4', 'dist5',\n#     'dist6', 'dist7', 'dist8', 'dist9', 'dist10',\n#     'dist11', 'dist12', 'dist13', 'dist14', 'dist15']] = dists","metadata":{"execution":{"iopub.status.busy":"2023-01-09T05:22:41.695606Z","iopub.execute_input":"2023-01-09T05:22:41.695979Z","iopub.status.idle":"2023-01-09T05:22:49.517074Z","shell.execute_reply.started":"2023-01-09T05:22:41.695951Z","shell.execute_reply":"2023-01-09T05:22:49.515604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df['number_houses_per_block'] = df['Population'] / df['AveOccup']\n# df['total_income_of_block'] = df['MedInc'] * df['Population']\n# df['occupants_to_bedrooms'] = df['AveOccup'] / df['AveBedrms']\n# df['total_number_of_rooms'] = df['AveBedrms'] + df['AveRooms']\n# df['bedrooms_to_rooms'] = df['AveBedrms'] / df['AveRooms']\n# df['occupants_to_rooms'] = df['AveOccup'] / df['AveRooms']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-01-09T07:44:27.466308Z","iopub.execute_input":"2023-01-09T07:44:27.466899Z","iopub.status.idle":"2023-01-09T07:44:27.572853Z","shell.execute_reply.started":"2023-01-09T07:44:27.466794Z","shell.execute_reply":"2023-01-09T07:44:27.570835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = df.iloc[:-len(test_df),:]\ntest_df = df.iloc[-len(test_df):,:].drop('MedHouseVal', axis=1).reset_index(drop=True)\n\nX = train_df.drop(['MedHouseVal', 'id'], axis=1)\ny = train_df.MedHouseVal\nX_test = test_df.drop('id', axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:27:29.723849Z","iopub.execute_input":"2023-01-09T04:27:29.724409Z","iopub.status.idle":"2023-01-09T04:27:29.747813Z","shell.execute_reply.started":"2023-01-09T04:27:29.724375Z","shell.execute_reply":"2023-01-09T04:27:29.746673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Catboost model**","metadata":{}},{"cell_type":"code","source":"import catboost\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\n\nn_folds = 15\n\nMAX_ITER = 15000\nPATIENCE = 1000\nDISPLAY_FREQ = 100\n\neval_predsCB = []\npredsCB = []\n\nk_fold = KFold(n_splits=n_folds, random_state=42, shuffle=True)\n\nMODEL_PARAMS = {\n                'random_seed': 1234,    \n#                 'learning_rate': 0.1,   # 0.15: 0.5678, 0.12: 0.5685, 0.1: 0.56757, 0.05: 0.57, 0.01, 0.57             \n                'iterations': MAX_ITER,\n                'early_stopping_rounds': PATIENCE,\n#                 'metric_period': DISPLAY_FREQ,\n                'use_best_model': True,\n                'eval_metric': 'RMSE',\n                'verbose': 1000,\n#                 'task_type': 'GPU'\n               }\n\n\nfor train_index, test_index in k_fold.split(X, y):\n    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n    \n    model = catboost.CatBoostRegressor(**MODEL_PARAMS)\n    \n    model.fit(X=X_train, y=y_train,\n          eval_set=[(X_valid, y_valid)],\n          early_stopping_rounds = PATIENCE,\n#           metric_period = DISPLAY_FREQ\n         )\n    predsCB.append(model.predict(X_test))\n#     eval_predsCB.append(model.predict(X))\n#     print(\"RMSE valid = {}\".format(mean_squared_error(y_valid, model.predict(X_valid))))\n#     print(\"RMSE full = {}\".format(mean_squared_error(y, model.predict(X))))","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:27:29.749171Z","iopub.execute_input":"2023-01-09T04:27:29.749837Z","iopub.status.idle":"2023-01-09T04:27:56.12573Z","shell.execute_reply.started":"2023-01-09T04:27:29.749801Z","shell.execute_reply":"2023-01-09T04:27:56.124022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**XGBoost model**","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\n\n# n_folds = 20\nk_fold = KFold(n_splits=n_folds, random_state=42, shuffle=True)\n\neval_predsXB = []\npredsXB = []\n\nPATIENCE = 200\n\nMODEL_PARAMS = {       'n_estimators': 1000, #1000, 5000\n#                        'learning_rate': 0.05,\n                       'max_depth': 4, # 3\n                       'colsample_bytree': 0.9, # 0.95\n                       'subsample': 1,\n                       'reg_lambda': 20,\n                       'early_stopping_rounds': PATIENCE,\n#                        'tree_method': 'gpu_hist',\n                       'seed': 1\n}\n\nfor train_index, test_index in k_fold.split(X, y):\n    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n    \n    model = XGBRegressor(**MODEL_PARAMS)\n    \n    model.fit(X=X_train, y=y_train,\n          eval_set=[(X_valid, y_valid)],\n#           early_stopping_rounds = PATIENCE,\n          verbose = 100\n         )\n    predsXB.append(model.predict(X_test))\n#     eval_predsXB.append(model.predict(X))","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:27:56.126634Z","iopub.status.idle":"2023-01-09T04:27:56.127019Z","shell.execute_reply.started":"2023-01-09T04:27:56.126845Z","shell.execute_reply":"2023-01-09T04:27:56.126862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LGBM model**","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgbm\nfrom lightgbm.sklearn import LGBMRegressor\n\n# n_folds = 20\nk_fold = KFold(n_splits=n_folds, random_state=42, shuffle=True)\n\neval_predsLB = []\npredsLB = []\n\nMODEL_PARAMS = {\n                       'learning_rate': 0.01,\n                       'max_depth': 9,\n                       'num_leaves': 90,\n                       'colsample_bytree': 0.8,\n                       'subsample': 0.9,\n                       'subsample_freq': 5,\n                       'min_child_samples': 36,\n                       'reg_lambda': 28,\n                       'n_estimators': 20000,\n                       'metric': 'rmse',\n                       'random_state': 1\n}\n\ncallbacks = [lgbm.early_stopping(30, verbose=1), lgbm.log_evaluation(period=0)]\n\nfor train_index, test_index in k_fold.split(X, y):\n    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n    \n    model = lgbm.LGBMRegressor(**MODEL_PARAMS)\n    \n    model.fit(X=X_train, y=y_train,\n          eval_set=[(X_valid, y_valid)],\n#           early_stopping_rounds = PATIENCE,\n          callbacks=callbacks\n         )\n    predsLB.append(model.predict(X_test))\n#     eval_predsLB.append(model.predict(X))","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:27:56.128317Z","iopub.status.idle":"2023-01-09T04:27:56.128765Z","shell.execute_reply.started":"2023-01-09T04:27:56.128551Z","shell.execute_reply":"2023-01-09T04:27:56.128573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mean_squared_error(y, np.average(np.array(eval_predsCB),axis=0), squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:27:56.129835Z","iopub.status.idle":"2023-01-09T04:27:56.13034Z","shell.execute_reply.started":"2023-01-09T04:27:56.130051Z","shell.execute_reply":"2023-01-09T04:27:56.130071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mean_squared_error(y, np.average(np.array(eval_predsXB),axis=0), squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:27:56.133651Z","iopub.status.idle":"2023-01-09T04:27:56.134155Z","shell.execute_reply.started":"2023-01-09T04:27:56.133946Z","shell.execute_reply":"2023-01-09T04:27:56.133969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mean_squared_error(y, np.average(np.array(eval_predsLB),axis=0), squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:27:56.135883Z","iopub.status.idle":"2023-01-09T04:27:56.136281Z","shell.execute_reply.started":"2023-01-09T04:27:56.136093Z","shell.execute_reply":"2023-01-09T04:27:56.136111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = 0.4\nb = 0.2\nc = 0.4","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:27:56.137439Z","iopub.status.idle":"2023-01-09T04:27:56.137729Z","shell.execute_reply.started":"2023-01-09T04:27:56.137592Z","shell.execute_reply":"2023-01-09T04:27:56.137605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mean_squared_error(y, a* np.average(np.array(eval_predsCB),axis=0) + b* np.average(np.array(eval_predsXB),axis=0) + c* np.average(np.array(eval_predsLB),axis=0), squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:27:56.139421Z","iopub.status.idle":"2023-01-09T04:27:56.139896Z","shell.execute_reply.started":"2023-01-09T04:27:56.139672Z","shell.execute_reply":"2023-01-09T04:27:56.139696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Making prediction**","metadata":{}},{"cell_type":"code","source":"predCB = np.average(np.array(predsCB),axis=0)\npredXB = np.average(np.array(predsXB),axis=0)\npredLB = np.average(np.array(predsLB),axis=0)\npred = predCB * a + predXB * b + predLB * c","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:27:56.141118Z","iopub.status.idle":"2023-01-09T04:27:56.141471Z","shell.execute_reply.started":"2023-01-09T04:27:56.141317Z","shell.execute_reply":"2023-01-09T04:27:56.141332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Making submission**","metadata":{}},{"cell_type":"code","source":"submission['MedHouseVal'] = pred\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:27:56.142587Z","iopub.status.idle":"2023-01-09T04:27:56.142924Z","shell.execute_reply.started":"2023-01-09T04:27:56.142757Z","shell.execute_reply":"2023-01-09T04:27:56.142772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vals = train_df['MedHouseVal'].unique().tolist()\nsubmission['MedHouseVal'] = submission['MedHouseVal'].apply(lambda x: min(vals, key=lambda v: abs(v - x)))\nsubmission.MedHouseVal.clip(0, 5, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:27:56.144569Z","iopub.status.idle":"2023-01-09T04:27:56.1449Z","shell.execute_reply.started":"2023-01-09T04:27:56.144737Z","shell.execute_reply":"2023-01-09T04:27:56.144755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T04:27:56.14561Z","iopub.status.idle":"2023-01-09T04:27:56.145884Z","shell.execute_reply.started":"2023-01-09T04:27:56.145746Z","shell.execute_reply":"2023-01-09T04:27:56.145759Z"},"trusted":true},"execution_count":null,"outputs":[]}]}