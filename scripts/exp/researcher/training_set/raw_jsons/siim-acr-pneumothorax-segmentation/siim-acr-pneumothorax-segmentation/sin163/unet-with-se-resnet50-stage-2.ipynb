{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install albumentations==0.4.6\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-22T00:12:50.332997Z","iopub.execute_input":"2023-08-22T00:12:50.333631Z","iopub.status.idle":"2023-08-22T00:12:50.338678Z","shell.execute_reply.started":"2023-08-22T00:12:50.333585Z","shell.execute_reply":"2023-08-22T00:12:50.337352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport pdb\nimport time\nimport warnings\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm_notebook as tqdm\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.model_selection import StratifiedKFold\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset, sampler\nfrom matplotlib import pyplot as plt\nfrom albumentations import (MultiplicativeNoise,HorizontalFlip,OpticalDistortion,VerticalFlip,GridDistortion,RandomBrightnessContrast,OneOf,ElasticTransform,RandomGamma,IAAEmboss,Blur,RandomRotate90,Transpose, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\nfrom albumentations.pytorch import ToTensorV2\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:12:50.340599Z","iopub.execute_input":"2023-08-22T00:12:50.34107Z","iopub.status.idle":"2023-08-22T00:12:50.352724Z","shell.execute_reply.started":"2023-08-22T00:12:50.341031Z","shell.execute_reply":"2023-08-22T00:12:50.351717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\nA.MultiplicativeNoise()","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:12:50.355022Z","iopub.execute_input":"2023-08-22T00:12:50.355545Z","iopub.status.idle":"2023-08-22T00:12:50.37055Z","shell.execute_reply.started":"2023-08-22T00:12:50.355506Z","shell.execute_reply":"2023-08-22T00:12:50.369524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install segmentation-models-pytorch","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:12:50.373776Z","iopub.execute_input":"2023-08-22T00:12:50.374217Z","iopub.status.idle":"2023-08-22T00:13:02.754789Z","shell.execute_reply.started":"2023-08-22T00:12:50.37418Z","shell.execute_reply":"2023-08-22T00:13:02.753306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**UTILITY FUN**","metadata":{}},{"cell_type":"code","source":"import segmentation_models_pytorch as smp","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:02.759218Z","iopub.execute_input":"2023-08-22T00:13:02.759546Z","iopub.status.idle":"2023-08-22T00:13:02.76521Z","shell.execute_reply.started":"2023-08-22T00:13:02.759511Z","shell.execute_reply":"2023-08-22T00:13:02.764161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_length_decode(rle, height=1024, width=1024, fill_value=1):\n    component = np.zeros((height, width), np.float32)\n    component = component.reshape(-1)\n    rle = np.array([int(s) for s in rle.strip().split(' ')])\n    rle = rle.reshape(-1, 2)\n    start = 0\n    for index, length in rle:\n        start = start+index\n        end = start+length\n        component[start: end] = fill_value\n        start = end\n    component = component.reshape(width, height).T\n    return component\n\ndef run_length_encode(component):\n    component = component.T.flatten()\n    start = np.where(component[1:] > component[:-1])[0]+1\n    end = np.where(component[:-1] > component[1:])[0]+1\n    length = end-start\n    rle = []\n    for i in range(len(length)):\n        if i == 0:\n            rle.extend([start[0], length[0]])\n        else:\n            rle.extend([start[i]-end[i-1], length[i]])\n    rle = ' '.join([str(r) for r in rle])\n    return rle","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:02.767065Z","iopub.execute_input":"2023-08-22T00:13:02.767503Z","iopub.status.idle":"2023-08-22T00:13:02.782297Z","shell.execute_reply.started":"2023-08-22T00:13:02.767459Z","shell.execute_reply":"2023-08-22T00:13:02.781205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DATA LOADER**","metadata":{}},{"cell_type":"code","source":"class SIIMDataset(Dataset):\n    def __init__(self, df, fnames, data_folder, size, mean, std, phase):\n        self.df = df\n        self.root = data_folder\n        self.size = size\n        self.mean = mean\n        self.std = std\n        self.phase = phase\n        self.transforms = get_transforms(phase, size, mean, std)\n        self.gb = self.df.groupby('ImageId')\n        self.fnames = fnames\n\n    def __getitem__(self, idx):\n        image_id = self.fnames[idx]\n        df = self.gb.get_group(image_id)\n        annotations = df[' EncodedPixels'].tolist()\n        image_path = os.path.join(self.root, image_id + \".png\")\n        image = cv2.imread(image_path)\n        mask = np.zeros([1024, 1024])\n        if annotations[0] != '-1':\n            for rle in annotations:\n                mask += run_length_decode(rle)\n        mask = (mask >= 1).astype('float32') # for overlap cases\n        augmented = self.transforms(image=image, mask=mask)\n        image = augmented['image']\n        mask = augmented['mask']\n        return image, mask\n\n    def __len__(self):\n        return len(self.fnames)\n\n\ndef get_transforms(phase, size, mean, std):\n    list_transforms = []\n    if phase == \"train\":\n        list_transforms.extend(\n            [\n                 HorizontalFlip(p=0.5),\n                ShiftScaleRotate(\n                    shift_limit=0,  # no resizing\n                    scale_limit=0.1,\n                    rotate_limit=10, # rotate\n                    p=0.5,\n                    border_mode=cv2.BORDER_CONSTANT\n                ),\n                 GaussNoise(),\n                A.MultiplicativeNoise(multiplier=1.5, p=1),\n            ]\n        )\n    list_transforms.extend(\n        [\n            Resize(size, size),\n            Normalize(mean=mean, std=std, p=1),\n            ToTensorV2(),\n        ]\n    )\n\n    list_trfms = Compose(list_transforms)\n    return list_trfms\n\ndef provider(\n    fold,\n    total_folds,\n    data_folder,\n    df_path,\n    phase,\n    size,\n    mean=None,\n    std=None,\n    batch_size=8,\n    num_workers=2,\n):\n    df_all = pd.read_csv(df_path)\n    df = df_all.drop_duplicates('ImageId')\n    df_with_mask = df[df[\" EncodedPixels\"] != \"-1\"]\n    df_with_mask['has_mask'] = 1\n    df_without_mask = df[df[\" EncodedPixels\"] == \"-1\"]\n    df_without_mask['has_mask'] = 0\n    df_without_mask_sampled = df_without_mask.sample(len(df_with_mask)+1500, random_state=2019) # random state is imp\n    df = pd.concat([df_with_mask, df_without_mask_sampled])\n    \n    #NOTE: equal number of positive and negative cases are chosen.\n    \n    kfold = StratifiedKFold(total_folds, shuffle=True, random_state=43)\n    train_idx, val_idx = list(kfold.split(df[\"ImageId\"], df[\"has_mask\"]))[fold]\n    train_df, val_df = df.iloc[train_idx], df.iloc[val_idx]\n    df = train_df if phase == \"train\" else val_df\n    # NOTE: total_folds=5 -> train/val : 80%/20%\n    \n    fnames = df['ImageId'].values\n    \n    image_dataset = SIIMDataset(df_all, fnames, data_folder, size, mean, std, phase)\n\n    dataloader = DataLoader(\n        image_dataset,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        pin_memory=True,\n        shuffle=True,\n    )\n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:02.784175Z","iopub.execute_input":"2023-08-22T00:13:02.784544Z","iopub.status.idle":"2023-08-22T00:13:02.817686Z","shell.execute_reply.started":"2023-08-22T00:13:02.784507Z","shell.execute_reply":"2023-08-22T00:13:02.816555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nprint(os.listdir('../input/'))","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:02.819492Z","iopub.execute_input":"2023-08-22T00:13:02.819965Z","iopub.status.idle":"2023-08-22T00:13:02.833626Z","shell.execute_reply.started":"2023-08-22T00:13:02.819887Z","shell.execute_reply":"2023-08-22T00:13:02.832423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission_path = '../input/siimmy/stage_2_sample_submission.csv'\ntrain_rle_path = '../input/mysiim/train-rle.csv'\ndata_folder = \"../input/siimpng/siimpng/train_png\"\ntest_data_folder = \"../input/siim_stage2_png\"","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:02.837745Z","iopub.execute_input":"2023-08-22T00:13:02.838298Z","iopub.status.idle":"2023-08-22T00:13:02.844323Z","shell.execute_reply.started":"2023-08-22T00:13:02.838258Z","shell.execute_reply":"2023-08-22T00:13:02.843176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nab = glob.glob('../input/siimpng/siimpng/train_png/*.png')\nlen(ab)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:02.845982Z","iopub.execute_input":"2023-08-22T00:13:02.846679Z","iopub.status.idle":"2023-08-22T00:13:02.910793Z","shell.execute_reply.started":"2023-08-22T00:13:02.846641Z","shell.execute_reply":"2023-08-22T00:13:02.909608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a= pd.read_csv(train_rle_path)\nlen(a)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:02.912626Z","iopub.execute_input":"2023-08-22T00:13:02.913023Z","iopub.status.idle":"2023-08-22T00:13:02.977411Z","shell.execute_reply.started":"2023-08-22T00:13:02.912981Z","shell.execute_reply":"2023-08-22T00:13:02.976213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from albumentations.pytorch import ToTensorV2","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:02.979082Z","iopub.execute_input":"2023-08-22T00:13:02.979559Z","iopub.status.idle":"2023-08-22T00:13:02.985204Z","shell.execute_reply.started":"2023-08-22T00:13:02.979517Z","shell.execute_reply":"2023-08-22T00:13:02.984007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from albumentations.pytorch import ToTensorV2\ndataloader = provider(\n    fold=0,\n    total_folds=5,\n    data_folder=data_folder,\n    df_path=train_rle_path,\n    phase=\"train\",\n    size=512,\n    mean = (0.485, 0.456, 0.406),\n    std = (0.229, 0.224, 0.225),\n    batch_size=16,\n    num_workers=2,\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:02.986658Z","iopub.execute_input":"2023-08-22T00:13:02.987636Z","iopub.status.idle":"2023-08-22T00:13:03.063922Z","shell.execute_reply.started":"2023-08-22T00:13:02.987589Z","shell.execute_reply":"2023-08-22T00:13:03.062912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch = next(iter(dataloader)) # get a batch from the dataloader\nimages,masks = batch #masks chilo target","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:03.065364Z","iopub.execute_input":"2023-08-22T00:13:03.065803Z","iopub.status.idle":"2023-08-22T00:13:07.861082Z","shell.execute_reply.started":"2023-08-22T00:13:03.065763Z","shell.execute_reply":"2023-08-22T00:13:07.859719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot some random images in the `batch`\nidx = random.choice(range(16))\nprint(masks[idx].shape)\nplt.imshow(images[idx][0], cmap='bone')\nplt.imshow(masks[idx], alpha=0.2, cmap='Reds')\nplt.show()\nif len(np.unique(masks[idx][0])) == 1: # only zeros\n    print('Chosen image has no ground truth mask, rerun the cell')","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:07.863182Z","iopub.execute_input":"2023-08-22T00:13:07.863574Z","iopub.status.idle":"2023-08-22T00:13:08.193263Z","shell.execute_reply.started":"2023-08-22T00:13:07.863527Z","shell.execute_reply":"2023-08-22T00:13:08.192194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Losses**\nThis kernel uses a weighted sum of Focal Loss and Dice Loss, let's call it MixedLoss","metadata":{}},{"cell_type":"code","source":"def dice_loss(input, target):\n    input = torch.sigmoid(input)\n    smooth = 1.0\n    iflat = input.view(-1)\n    tflat = target.view(-1)\n    #tflat = np.reshape(target,(4, 1, 512, 512))\n    intersection = (iflat * tflat).sum()\n    return ((2.0 * intersection + smooth) / (iflat.sum() + tflat.sum() + smooth))\n\n\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma):\n        super().__init__()\n        self.gamma = gamma\n\n    def forward(self, input, target):\n        if not (target.size() == input.size()):\n            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n                             .format(target.size(), input.size()))\n        max_val = (-input).clamp(min=0)\n        loss = input - input * target + max_val + \\\n            ((-max_val).exp() + (-input - max_val).exp()).log()\n        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n        loss = (invprobs * self.gamma).exp() * loss\n        return loss.mean()\n\n\nclass MixedLoss(nn.Module):\n    def __init__(self, alpha, gamma):\n        super().__init__()\n        self.alpha = alpha\n        self.focal = FocalLoss(gamma)\n\n    def forward(self, input, target):\n        loss = self.alpha*self.focal(input, target) - torch.log(dice_loss(input, target))\n        return loss.mean()","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:08.194891Z","iopub.execute_input":"2023-08-22T00:13:08.195951Z","iopub.status.idle":"2023-08-22T00:13:08.212362Z","shell.execute_reply.started":"2023-08-22T00:13:08.195911Z","shell.execute_reply":"2023-08-22T00:13:08.211294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Some more utility functions\nHere are some utility functions for calculating IoU and Dice scores**","metadata":{}},{"cell_type":"code","source":"def predict(X, threshold):\n    X_p = np.copy(X)\n    preds = (X_p > threshold).astype('uint8')\n    return preds\n\ndef metric(probability, truth, threshold=0.5, reduction='none'):\n    '''Calculates dice of positive and negative images seperately'''\n    '''probability and truth must be torch tensors'''\n    batch_size = len(truth)\n    with torch.no_grad():\n        probability = probability.view(batch_size, -1)\n        truth = truth.view(batch_size, -1)\n        assert(probability.shape == truth.shape)\n\n        p = (probability > threshold).float()\n        t = (truth > 0.5).float()\n\n        t_sum = t.sum(-1)\n        p_sum = p.sum(-1)\n        neg_index = torch.nonzero(t_sum == 0)\n        pos_index = torch.nonzero(t_sum >= 1)\n\n        dice_neg = (p_sum == 0).float()\n        dice_pos = 2 * (p*t).sum(-1)/((p+t).sum(-1))\n\n        dice_neg = dice_neg[neg_index]\n        dice_pos = dice_pos[pos_index]\n        dice = torch.cat([dice_pos, dice_neg])\n\n        dice_neg = np.nan_to_num(dice_neg.mean().item(), 0)\n        dice_pos = np.nan_to_num(dice_pos.mean().item(), 0)\n        dice = dice.mean().item()\n\n        num_neg = len(neg_index)\n        num_pos = len(pos_index)\n\n    return dice, dice_neg, dice_pos, num_neg, num_pos\n\nclass Meter:\n    '''A meter to keep track of iou and dice scores throughout an epoch'''\n    def __init__(self, phase, epoch):\n        self.base_threshold = 0.5 # <<<<<<<<<<< here's the threshold\n        self.base_dice_scores = []\n        self.dice_neg_scores = []\n        self.dice_pos_scores = []\n        self.iou_scores = []\n\n    def update(self, targets, outputs):\n        probs = torch.sigmoid(outputs)\n        dice, dice_neg, dice_pos, _, _ = metric(probs, targets, self.base_threshold)\n        self.base_dice_scores.append(dice)\n        self.dice_pos_scores.append(dice_pos)\n        self.dice_neg_scores.append(dice_neg)\n        preds = predict(probs, self.base_threshold)\n        iou = compute_iou_batch(preds, targets, classes=[1])\n        self.iou_scores.append(iou)\n\n    def get_metrics(self):\n        dice = np.mean(self.base_dice_scores)\n        dice_neg = np.mean(self.dice_neg_scores)\n        dice_pos = np.mean(self.dice_pos_scores)\n        dices = [dice, dice_neg, dice_pos]\n        iou = np.nanmean(self.iou_scores)\n        return dices, iou\n\ndef epoch_log(phase, epoch, epoch_loss, meter, start):\n    '''logging the metrics at the end of an epoch'''\n    dices, iou = meter.get_metrics()\n    dice, dice_neg, dice_pos = dices\n    print(\"Loss: %0.4f | dice: %0.4f | dice_neg: %0.4f | dice_pos: %0.4f | IoU: %0.4f\" % (epoch_loss, dice, dice_neg, dice_pos, iou))\n    return dice, iou\n\ndef compute_ious(pred, label, classes, ignore_index=255, only_present=True):\n    '''computes iou for one ground truth mask and predicted mask'''\n    pred[label == ignore_index] = 0\n    ious = []\n    for c in classes:\n        label_c = label == c\n        if only_present and np.sum(label_c) == 0:\n            ious.append(np.nan)\n            continue\n        pred_c = pred == c\n        intersection = np.logical_and(pred_c, label_c).sum()\n        union = np.logical_or(pred_c, label_c).sum()\n        if union != 0:\n            ious.append(intersection / union)\n    return ious if ious else [1]\n\n\ndef compute_iou_batch(outputs, labels, classes=None):\n    '''computes mean iou for a batch of ground truth masks and predicted masks'''\n    ious = []\n    preds = np.copy(outputs) # copy is imp\n    labels = np.array(labels) # tensor to np\n    for pred, label in zip(preds, labels):\n        ious.append(np.nanmean(compute_ious(pred, label, classes)))\n    iou = np.nanmean(ious)\n    return iou\n","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:08.215844Z","iopub.execute_input":"2023-08-22T00:13:08.216207Z","iopub.status.idle":"2023-08-22T00:13:08.243196Z","shell.execute_reply.started":"2023-08-22T00:13:08.216171Z","shell.execute_reply":"2023-08-22T00:13:08.242098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = smp.FPN('inceptionresnetv2', encoder_weights=\"imagenet\")","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:08.245756Z","iopub.execute_input":"2023-08-22T00:13:08.246568Z","iopub.status.idle":"2023-08-22T00:13:08.257891Z","shell.execute_reply.started":"2023-08-22T00:13:08.24653Z","shell.execute_reply":"2023-08-22T00:13:08.256868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = smp.Unet(\"resnet34\", encoder_weights=\"imagenet\", activation=None)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:08.259396Z","iopub.execute_input":"2023-08-22T00:13:08.259882Z","iopub.status.idle":"2023-08-22T00:13:08.905836Z","shell.execute_reply.started":"2023-08-22T00:13:08.259842Z","shell.execute_reply":"2023-08-22T00:13:08.904702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:08.907228Z","iopub.execute_input":"2023-08-22T00:13:08.908008Z","iopub.status.idle":"2023-08-22T00:13:08.919738Z","shell.execute_reply.started":"2023-08-22T00:13:08.907959Z","shell.execute_reply":"2023-08-22T00:13:08.9185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import math\nimport torch\nfrom torch.optim.optimizer import Optimizer, required\n\nclass RAdam(Optimizer):\n\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n        self.buffer = [[None, None, None] for ind in range(10)]\n        super(RAdam, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(RAdam, self).__setstate__(state)\n\n    def step(self, closure=None):\n\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data.float()\n                if grad.is_sparse:\n                    raise RuntimeError('RAdam does not support sparse gradients')\n\n                p_data_fp32 = p.data.float()\n\n                state = self.state[p]\n\n                if len(state) == 0:\n                    state['step'] = 0\n                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n                else:\n                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n                beta1, beta2 = group['betas']\n\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n\n                state['step'] += 1\n                buffered = self.buffer[int(state['step'] % 10)]\n                if state['step'] == buffered[0]:\n                    N_sma, step_size = buffered[1], buffered[2]\n                else:\n                    buffered[0] = state['step']\n                    beta2_t = beta2 ** state['step']\n                    N_sma_max = 2 / (1 - beta2) - 1\n                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n                    buffered[1] = N_sma\n\n                    # more conservative since it's an approximated value\n                    if N_sma >= 5:\n                        step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n                    else:\n                        step_size = group['lr'] / (1 - beta1 ** state['step'])\n                    buffered[2] = step_size\n\n                if group['weight_decay'] != 0:\n                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n\n                # more conservative since it's an approximated value\n                if N_sma >= 5:            \n                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n                else:\n                    p_data_fp32.add_(-step_size, exp_avg)\n\n                p.data.copy_(p_data_fp32)\n\n        return loss","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:08.926064Z","iopub.execute_input":"2023-08-22T00:13:08.926452Z","iopub.status.idle":"2023-08-22T00:13:08.949923Z","shell.execute_reply.started":"2023-08-22T00:13:08.926422Z","shell.execute_reply":"2023-08-22T00:13:08.948677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer(object):\n    '''This class takes care of training and validation of our model'''\n    def __init__(self, model):\n        self.fold = 1\n        self.total_folds = 5\n        self.num_workers = 4\n        self.batch_size = {\"train\": 4, \"val\": 4}\n        self.accumulation_steps = 32 // self.batch_size['train']\n        self.lr = 5e-4\n        self.num_epochs = 40\n        self.best_loss = float(\"inf\")\n        self.phases = [\"train\", \"val\"]\n        self.device = torch.device(\"cuda\")\n        #torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n        self.net = model\n        self.criterion = MixedLoss(10.0, 2.0)\n        #self.optimizer = optim.Adam(self.net.parameters(), lr=self.lr)\n        self.optimizer = RAdam(model.parameters(), lr=self.lr)\n\n        self.scheduler = ReduceLROnPlateau(self.optimizer, mode=\"min\", patience=3, verbose=True)\n        self.net = self.net.to(self.device)\n        cudnn.benchmark = True\n        self.dataloaders = {\n            phase: provider(\n                fold=1,\n                total_folds=5,\n                data_folder=data_folder,\n                df_path=train_rle_path,\n                phase=phase,\n                size=512,\n                mean=(0.485, 0.456, 0.406),\n                std=(0.229, 0.224, 0.225),\n                batch_size=self.batch_size[phase],\n                num_workers=self.num_workers,\n            )\n            for phase in self.phases\n        }\n        self.losses = {phase: [] for phase in self.phases}\n        self.iou_scores = {phase: [] for phase in self.phases}\n        self.dice_scores = {phase: [] for phase in self.phases}\n        \n    def forward(self, images, targets):\n        images = images.to(self.device)\n        masks = targets.to(self.device)\n        outputs = self.net(images)\n        loss = self.criterion(outputs, masks)\n        return loss, outputs\n\n    def iterate(self, epoch, phase):\n        meter = Meter(phase, epoch)\n        start = time.strftime(\"%H:%M:%S\")\n        print(f\"Starting epoch: {epoch} | phase: {phase} | ‚è∞: {start}\")\n        batch_size = self.batch_size[phase]\n        self.net.train(phase == \"train\")\n        dataloader = self.dataloaders[phase]\n        running_loss = 0.0\n        total_batches = len(dataloader)\n#         tk0 = tqdm(dataloader, total=total_batches)\n        self.optimizer.zero_grad()\n        for itr, batch in enumerate(dataloader):\n            images, targets = batch\n            targets = targets.unsqueeze(1)\n            loss, outputs = self.forward(images, targets)\n            loss = loss / self.accumulation_steps\n            if phase == \"train\":\n                loss.backward()\n                if (itr + 1 ) % self.accumulation_steps == 0:\n                    self.optimizer.step()\n                    self.optimizer.zero_grad()\n            running_loss += loss.item()\n            outputs = outputs.detach().cpu()\n            meter.update(targets, outputs)\n#             tk0.set_postfix(loss=(running_loss / ((itr + 1))))\n        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n        dice, iou = epoch_log(phase, epoch, epoch_loss, meter, start)\n        self.losses[phase].append(epoch_loss)\n        self.dice_scores[phase].append(dice)\n        self.iou_scores[phase].append(iou)\n        torch.cuda.empty_cache()\n        return epoch_loss\n\n    def start(self):\n        for epoch in range(self.num_epochs):\n            self.iterate(epoch, \"train\")\n            state = {\n                \"epoch\": epoch,\n                \"best_loss\": self.best_loss,\n                \"state_dict\": self.net.state_dict(),\n                \"optimizer\": self.optimizer.state_dict(),\n            }\n            val_loss = self.iterate(epoch, \"val\")\n            self.scheduler.step(val_loss)\n            if val_loss < self.best_loss:\n                print(\"******** New optimal found, saving state ********\")\n                state[\"best_loss\"] = self.best_loss = val_loss\n                torch.save(state, \"./model.pth\")\n            print()","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:08.952781Z","iopub.execute_input":"2023-08-22T00:13:08.953535Z","iopub.status.idle":"2023-08-22T00:13:08.980939Z","shell.execute_reply.started":"2023-08-22T00:13:08.953495Z","shell.execute_reply":"2023-08-22T00:13:08.979808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_trainer = Trainer(model)\nmodel_trainer.start()","metadata":{"execution":{"iopub.status.busy":"2023-08-22T00:13:08.982461Z","iopub.execute_input":"2023-08-22T00:13:08.98405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PLOT TRAINING\nlosses = model_trainer.losses\ndice_scores = model_trainer.dice_scores # overall dice\niou_scores = model_trainer.iou_scores\n\ndef plot(scores, name):\n    plt.figure(figsize=(15,5))\n    plt.plot(range(len(scores[\"train\"])), scores[\"train\"], label=f'train {name}')\n    plt.plot(range(len(scores[\"train\"])), scores[\"val\"], label=f'val {name}')\n    plt.title(f'{name} plot'); plt.xlabel('Epoch'); plt.ylabel(f'{name}');\n    plt.legend(); \n    plt.show()\n\nplot(losses, \"BCE loss\")\nplot(dice_scores, \"Dice score\")\nplot(iou_scores, \"IoU score\")\nprint(losses)\nprint(dice_scores)\nprint(iou_scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Test pred**","metadata":{}},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, root, df, size, mean, std, tta=4):\n        self.root = root\n        self.size = size\n        self.fnames = list(df[\"ImageId\"])\n        self.num_samples = len(self.fnames)\n        self.transform = Compose(\n            [\n                Normalize(mean=mean, std=std, p=1),\n                Resize(size, size),\n                ToTensorV2(),\n            ]\n        )\n\n    def __getitem__(self, idx):\n        fname = self.fnames[idx]\n        path = os.path.join(self.root, fname + \".png\")\n        image = cv2.imread(path)\n        images = self.transform(image=image)[\"image\"]\n        return images\n\n    def __len__(self):\n        return self.num_samples\n\ndef post_process(probability, threshold, min_size):\n    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n    predictions = np.zeros((1024, 1024), np.float32)\n    num = 0\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            predictions[p] = 1\n            num += 1\n    return predictions, num","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"size = 512\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\nnum_workers = 8\nbatch_size = 16\nbest_threshold = 0.5\nmin_size = 3500\ndevice = torch.device(\"cuda:0\")\ndf = pd.read_csv(sample_submission_path)\ntestset = DataLoader(\n    TestDataset(test_data_folder, df, size, mean, std),\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=num_workers,\n    pin_memory=True,\n)\nmodel = model_trainer.net # get the model from model_trainer object\nmodel.eval()\nstate = torch.load('./model.pth', map_location=lambda storage, loc: storage)\nmodel.load_state_dict(state[\"state_dict\"])\nencoded_pixels = []\nfor i, batch in enumerate(tqdm(testset)):\n    preds = torch.sigmoid(model(batch.to(device)))\n    preds = preds.detach().cpu().numpy()[:, 0, :, :] # (batch_size, 1, size, size) -> (batch_size, size, size)\n    for probability in preds:\n        if probability.shape != (1024, 1024):\n            probability = cv2.resize(probability, dsize=(1024, 1024), interpolation=cv2.INTER_LINEAR)\n        predict, num_predict = post_process(probability, best_threshold, min_size)\n        if num_predict == 0:\n            encoded_pixels.append('-1')\n        else:\n            r = run_length_encode(predict)\n            encoded_pixels.append(r)\ndf['EncodedPixels'] = encoded_pixels\ndf.to_csv('submission.csv', columns=['ImageId', 'EncodedPixels'], index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}