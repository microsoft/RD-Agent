{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom tqdm import tqdm\nimport gc\nimport time","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n#\ndef autocorrelation(ys, t=1):\n    return np.corrcoef(ys[:-t], ys[t:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Variables to help with aggregation**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#==========================================================================\ndef preprocess_sales(sales, start=1200, upper=1970):\n    if start is not None:\n        print(\"dropping...\")\n        to_drop = [f\"d_{i+1}\" for i in range(start-1)]\n        print(sales.shape)\n        sales.drop(to_drop, axis=1, inplace=True)\n        print(sales.shape)\n    #=======\n    print(\"adding...\")\n    new_columns = ['d_%i'%i for i in range(1942, upper, 1)]\n    for col in new_columns:\n        sales[col] = np.nan\n    print(\"melting...\")\n    sales = sales.melt(id_vars=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\",\"scale\",\"start\"],\n                        var_name='d', value_name='demand')\n\n    print(\"generating order\")\n    if start is not None:\n        skip = start\n    else:\n        skip = 1\n    sales[\"nb\"] =sales.index // 42840 + skip\n    return sales\n#===============================================================\ndef preprocess_calendar(calendar):\n    global maps, mods\n    calendar[\"event_name\"] = calendar[\"event_name_1\"]\n    calendar[\"event_type\"] = calendar[\"event_type_1\"]\n\n    map1 = {mod:i for i,mod in enumerate(calendar['event_name'].unique())}\n    calendar['event_name'] = calendar['event_name'].map(map1)\n    map2 = {mod:i for i,mod in enumerate(calendar['event_type'].unique())}\n    calendar['event_type'] = calendar['event_type'].map(map2)\n    calendar['nday'] = calendar['date'].str[-2:].astype(int)\n    maps[\"event_name\"] = map1\n    maps[\"event_type\"] = map2\n    mods[\"event_name\"] = len(map1)\n    mods[\"event_type\"] = len(map2)\n    calendar[\"wday\"] -=1\n    calendar[\"month\"] -=1\n    calendar[\"year\"] -= 2011\n    mods[\"month\"] = 12\n    mods[\"year\"] = 6\n    mods[\"wday\"] = 7\n    mods['snap_CA'] = 2\n    mods['snap_TX'] = 2\n    mods['snap_WI'] = 2\n\n    calendar.drop([\"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\", \"date\", \"weekday\"], \n                  axis=1, inplace=True)\n    return calendar\n#=========================================================\ndef make_dataset(categorize=False ,start=1400, upper= 1970):\n    global maps, mods\n    print(\"loading calendar...\")\n    calendar = pd.read_csv(\"../input/m5-forecasting-uncertainty/calendar.csv\")\n    print(\"loading sales...\")\n    sales = pd.read_csv(\"../input/walmartadd/sales.csv\")\n    cols = [\"item_id\", \"dept_id\", \"cat_id\",\"store_id\",\"state_id\"]\n    if categorize:\n        for col in cols:\n            temp_dct = {mod:i for i, mod in enumerate(sales[col].unique())}\n            mods[col] = len(temp_dct)\n            maps[col] = temp_dct\n        for col in cols:\n            sales[col] = sales[col].map(maps[col])\n        #\n\n    sales =preprocess_sales(sales, start=start, upper= upper)\n    calendar = preprocess_calendar(calendar)\n    calendar = reduce_mem_usage(calendar)\n    print(\"merge with calendar...\")\n    sales = sales.merge(calendar, on='d', how='left')\n    del calendar\n\n    print(\"reordering...\")\n    sales.sort_values(by=[\"id\",\"nb\"], inplace=True)\n    print(\"re-indexing..\")\n    sales.reset_index(inplace=True, drop=True)\n    gc.collect()\n\n    sales['n_week'] = (sales['nb']-1)//7\n    sales[\"nday\"] -= 1\n    mods['nday'] = 31\n    sales = reduce_mem_usage(sales)\n    gc.collect()\n    return sales\n#===================","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nCATEGORIZE = True;\nSTART = 1200; UPPER = 1970;\nmaps = {}\nmods = {}\nsales = make_dataset(categorize=CATEGORIZE ,start=START, upper= UPPER)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we are asked to predict a time window of 28 days, the easiest way to go now is to use the last 28 days for validation:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales[\"x\"] = sales[\"demand\"] / sales[\"scale\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LAGS = [28, 29, 30, 31, 32, 33]\nFEATS = []\nfor lag in tqdm(LAGS):\n    sales[f\"x_{lag}\"] = sales.groupby(\"id\")[\"x\"].shift(lag)\n    FEATS.append(f\"x_{lag}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sales.loc[(sales.start>1844)&(sales.nb>1840)&(sales.nb<1850), ['id','start','nb','demand']]\n#sales.start.max() #1845","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sales.shape)\nsales = sales.loc[sales.nb>sales.start]\nprint(sales.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### Apply on grid_df\nTARGET      = 'demand'\ngrid_df1 = sales[['id','d','demand']]\nSHIFT_DAY = 14\nSHIFT_DAY1 = 1\n\n# Lags\n# with 28 day shift\nstart_time = time.time()\nprint('Create lags')\n\n#LAG_DAYS = [col for col in range(SHIFT_DAY,SHIFT_DAY+15)]\nLAG_DAYS = [col for col in range(SHIFT_DAY,SHIFT_DAY+13)]\ngrid_df1 = grid_df1.assign(**{\n        '{}_lag_{}'.format(col, l): grid_df1.groupby(['id'])[col].transform(lambda x: x.shift(l))\n        for l in LAG_DAYS\n        for col in [TARGET]\n    })\n\n# Minify lag columns\nfor col in list(grid_df1):\n    if 'lag' in col:\n        grid_df1[col] = grid_df1[col].astype(np.float16)\n\nprint('%0.2f min: Lags' % ((time.time() - start_time) / 60))\n\n\n# Rollings\n# with 28 day shift\nstart_time = time.time()\nprint('Create rolling aggs')\n\n\n\n#for i in [7,14,30,60,180]:\n#for i in [7,14,35,63,168]:\nfor i in [7,14,30]:\n    print('Rolling period:', i)\n    grid_df1['rolling_mean_'+str(i)] = grid_df1.groupby(['id'])[TARGET].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).mean()).astype(np.float16)\n    grid_df1['rolling_std_'+str(i)]  = grid_df1.groupby(['id'])[TARGET].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).std()).astype(np.float16)\n\n\n    \nprint('%0.2f min: Lags' % ((time.time() - start_time) / 60))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_df1=grid_df1.drop(['demand'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### Merge prices and save part 2\n#################################################################################\nprint('Merge prices and save part 2')\n# Merge Prices\ngrid_df = sales.merge(grid_df1, on=['id','d'], how='left')\n#keep_columns = [col for col in list(sales) if col not in original_columns]\n#grid_df = grid_df[MAIN_INDEX+keep_columns]\n#grid_df = reduce_mem_usage(grid_df)\n\n# Safe part 2\n#grid_df.to_pickle('State_Item_1.pkl')\nprint('Size:', sales.shape)\n\n# We don't need prices_df anymore\ndel grid_df1\n\n\n# We can remove new columns\n# or just load part_1\n#grid_df = pd.read_pickle('grid_part_1.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb = sales['nb'].values\nMAX_LAG = max(LAGS)\n#tr_mask = np.logical_and(nb>START + MAX_LAG, nb<=1913)\ntr_mask = np.logical_and(nb>START + MAX_LAG, nb<=1941) \nval_mask = np.logical_and(nb>1913, nb<=1941)\nte_mask = np.logical_and(nb>1941, nb<=1969)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scale = sales['scale'].values\nids = sales['id'].values\n#y = sales['demand'].values\n#ys = y / scale\nys = sales['x'].values\nZ = sales[FEATS].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales['x']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scale","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sv = scale[val_mask]\nse = scale[te_mask]\nids = ids[te_mask]\nids = ids.reshape((-1, 28))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"se","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ca = sales[['snap_CA']].values\ntx = sales[['snap_TX']].values\nwi = sales[['snap_WI']].values\nwday = sales[['wday']].values\nmonth = sales[['month']].values\nyear = sales[['year']].values\nevent = sales[['event_name']].values\nnday = sales[['nday']].values\nlag1=sales[['x_28']].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item = sales[['item_id']].values\ndept = sales[['dept_id']].values\ncat = sales[['cat_id']].values\nstore = sales[['store_id']].values\nstate = sales[['state_id']].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Z","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales[FEATS]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ca","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_data(mask):\n    x = {\"snap_CA\":ca[mask], \"snap_TX\":tx[mask], \"snap_WI\":wi[mask], \"wday\":wday[mask], \n         \"month\":month[mask], \"year\":year[mask], \"event\":event[mask], \"nday\":nday[mask], \n         \"item\":item[mask], \"dept\":dept[mask], \"cat\":cat[mask], \"store\":store[mask], \n         \"state\":state[mask],\"num\":Z[mask]}\n    t = ys[mask]\n    return x, t","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xt, yt = make_data(tr_mask) #train\nxv, yv = make_data(val_mask) # val\nxe, ye = make_data(te_mask) # test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qs = [0.005, 0.025, 0.165, 0.250, 0.500, 0.750, 0.835, 0.975, 0.995]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q = tf.constant(np.array([qs]), dtype=tf.float32)\nq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ca = L.Input((1,), name=\"snap_CA\")\nca","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#=====\ndef qloss(y_true, y_pred):\n    # Pinball loss for multiple quantiles\n    qs = [0.005, 0.025, 0.165, 0.250, 0.500, 0.750, 0.835, 0.975, 0.995]\n    q = tf.constant(np.array([qs]), dtype=tf.float32)\n    e = y_true - y_pred\n    v = tf.maximum(q*e, (q-1)*e)\n    return K.mean(v)\n#============================#\ndef make_model(n_in):\n    \n    num = L.Input((n_in,), name=\"num\")\n    \n    ca = L.Input((1,), name=\"snap_CA\")\n    tx = L.Input((1,), name=\"snap_TX\")\n    wi = L.Input((1,), name=\"snap_WI\")\n    wday = L.Input((1,), name=\"wday\")\n    month = L.Input((1,), name=\"month\")\n    year = L.Input((1,), name=\"year\")\n    event = L.Input((1,), name=\"event\")\n    nday = L.Input((1,), name=\"nday\")\n    item = L.Input((1,), name=\"item\")\n    dept = L.Input((1,), name=\"dept\")\n    cat = L.Input((1,), name=\"cat\")\n    store = L.Input((1,), name=\"store\")\n    state = L.Input((1,), name=\"state\")\n    inp = {\"snap_CA\":ca, \"snap_TX\":tx, \"snap_WI\":wi, \"wday\":wday, \n           \"month\":month, \"year\":year, \"event\":event, \"nday\":nday,\n           \"item\":item, \"dept\":dept, \"cat\":cat, \"store\":store, \n           \"state\":state, \"num\":num} \n    #\n    ca_ = L.Embedding(mods[\"snap_CA\"], mods[\"snap_CA\"], name=\"ca_3d\")(ca)\n    tx_ = L.Embedding(mods[\"snap_TX\"], mods[\"snap_TX\"], name=\"tx_3d\")(tx)\n    wi_ = L.Embedding(mods[\"snap_WI\"], mods[\"snap_WI\"], name=\"wi_3d\")(wi)\n    wday_ = L.Embedding(mods[\"wday\"], mods[\"wday\"], name=\"wday_3d\")(wday)\n    month_ = L.Embedding(mods[\"month\"], mods[\"month\"], name=\"month_3d\")(month)\n    year_ = L.Embedding(mods[\"year\"], mods[\"year\"], name=\"year_3d\")(year)\n    event_ = L.Embedding(mods[\"event_name\"], mods[\"event_name\"], name=\"event_3d\")(event)\n    nday_ = L.Embedding(mods[\"nday\"], mods[\"nday\"], name=\"nday_3d\")(nday)\n    item_ = L.Embedding(mods[\"item_id\"], 10, name=\"item_3d\")(item)\n    dept_ = L.Embedding(mods[\"dept_id\"], mods[\"dept_id\"], name=\"dept_3d\")(dept)\n    cat_ = L.Embedding(mods[\"cat_id\"], mods[\"cat_id\"], name=\"cat_3d\")(cat)\n    store_ = L.Embedding(mods[\"store_id\"], mods[\"store_id\"], name=\"store_3d\")(store)\n    state_ = L.Embedding(mods[\"state_id\"], mods[\"state_id\"], name=\"state_3d\")(state)\n    \n    p = [ca_, tx_, wi_, wday_, month_, year_, event_, nday_, item_, dept_, cat_, store_, state_]\n    emb = L.Concatenate(name=\"embds\")(p)\n    context = L.Flatten(name=\"context\")(emb)\n    \n    x = L.Concatenate(name=\"x1\")([context, num])\n    x = L.Dense(500, activation=\"relu\", name=\"d1\")(x)\n    x = L.Dropout(0.3)(x)\n    x = L.Concatenate(name=\"m1\")([x, context])\n    x = L.Dense(500, activation=\"relu\", name=\"d2\")(x)\n    x = L.Dropout(0.3)(x)\n    x = L.Concatenate(name=\"m2\")([x, context])\n    x = L.Dense(500, activation=\"relu\", name=\"d3\")(x)\n    preds = L.Dense(9, activation=\"linear\", name=\"preds\")(x)\n    model = M.Model(inp, preds, name=\"M1\")\n    model.compile(loss=qloss, optimizer=\"adam\")\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = make_model(len(FEATS))\nckpt = ModelCheckpoint(\"w.h5\", monitor='val_loss', verbose=1, save_best_only=True,mode='min')\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=5, min_lr=0.001)\nes = EarlyStopping(monitor='val_loss', patience=3)\nprint(net.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net.fit(xt, yt, batch_size=50_000, epochs=20, validation_data=(xv, yv), callbacks=[ckpt, reduce_lr, es])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nett = make_model(len(FEATS))\nnett.load_weights(\"w.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pv = nett.predict(xv, batch_size=50_000, verbose=1)\npe = nett.predict(xe, batch_size=50_000, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nett.evaluate(xv, yv, batch_size=50_000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pv = pv.reshape((-1, 28, 9))\npe = pe.reshape((-1, 28, 9))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sv = sv.reshape((-1, 28))\nse = se.reshape((-1, 28))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Yv = yv.reshape((-1, 28))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k = np.random.randint(0, 42840)\n#k = np.random.randint(0, 200)\nprint(ids[k, 0])\nplt.plot(np.arange(28, 56), Yv[k], label=\"true\")\nplt.plot(np.arange(28, 56), pv[k ,:, 3], label=\"q25\")\nplt.plot(np.arange(28, 56), pv[k ,:, 4], label=\"q50\")\nplt.plot(np.arange(28, 56), pv[k, :, 5], label=\"q75\")\nplt.legend(loc=\"best\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names = [f\"F{i+1}\" for i in range(28)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"piv = pd.DataFrame(ids[:, 0], columns=[\"id\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"piv.head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"QUANTILES = [\"0.005\", \"0.025\", \"0.165\", \"0.250\", \"0.500\", \"0.750\", \"0.835\", \"0.975\", \"0.995\"]\nVALID = []\nEVAL = []\n\nfor i, quantile in tqdm(enumerate(QUANTILES)):\n    t1 = pd.DataFrame(pv[:,:, i]*sv, columns=names)\n    t1 = piv.join(t1)\n    t1[\"id\"] = t1[\"id\"] + f\"_{quantile}_validation\"\n    t2 = pd.DataFrame(pe[:,:, i]*se, columns=names)\n    t2 = piv.join(t2)\n    t2[\"id\"] = t2[\"id\"] + f\"_{quantile}_evaluation\"\n    VALID.append(t1)\n    EVAL.append(t2)\n#============#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame()\nsub = sub.append(VALID + EVAL)\ndel VALID, EVAL, t1, t2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}