scenario_problem:
  system: |-
    {% include "scenarios.data_science.share:scen.role" %}
    You will be given scenario and competition description and the current SOTA implementation and feedback.
    Your task is to analyze the given information and extract the **Scenario Problems** from the given materials.

    ## Scenario Problems
    ### Definition
    Scenario problems are specific, context-dependent challenges arising from a competition's dataset or domain. They fall into two categories:
    1. Dataset Characteristics: Inherent structural or statistical properties of the dataset (such as imbalance, high dimensionality, collinearity, outliers, missing data, skewed distribution, time-based patterns, etc.).
    2. Domain-specific Insights: Actionable knowledge derived from expertise in the competition's domain, enabling correct interpretation of data patterns or constraints. These insights are not evident from the data alone and require external context to resolve ambiguities, engineer features, or avoid invalid assumptions.

    ### Specification
    {{ problem_spec }}
    
    ### Core Analysis Dimensions
    1. SOTA Mismatch Diagnosis: Systematically compare current implementations against both data properties and domain knowledge to identify critical discrepancies.
    2. Gap Forensic Analysis: Examine successful solutions to reveal unstated problems they implicitly address through workarounds.
    3. Domain-Implementation Conflict Detection: Identify instances where technical approaches violate domain constraints or oversimplify complex relationships.

    ### Output Format
    {{ problem_output_format }}

  user: |-
    # Scenario Description
    {{ scenario_desc }}

    # Competition Description
    {{ competition_desc }}

    # Current SOTA Implementation
    {{ sota_exp_desc }}

feedback_problem:
  system: |-
    {% include "scenarios.data_science.share:scen.role" %}
    The user is improving a Kaggle competition implementation iteratively through traces where each new trace is modified from the current SOTA in the trace, not necessarily the immediate predecessor.
    You will be given a competition scenario, previous SOTA and failed experiments and feedbacks, and the current SOTA implementation and feedback.
    Your task is to analyze the given information and extract the **Low-Level Problems** from the current SOTA implementation.

    ## Low-Level Problems
    ### Definition
    Low-level problems are specific and fine-grained technical, or methodological issues within the implementation.
    
    ### Specification
    {{ problem_spec }}

    ### Output Format
    {{ problem_output_format }}

  user: |-
    # Scenario Description
    {{ scenario_desc }}
    
    # Previous Experiments and Feedbacks:
    {{ exp_and_feedback_list_desc }}    

    # Current SOTA Implementation
    {{ sota_exp_desc }}

hypothesis_gen:
  system: |-
    {% include "scenarios.data_science.share:scen.role" %}
    The user is improving a Kaggle competition implementation iteratively through traces where each new trace is modified from the current SOTA in the trace, not necessarily the immediate predecessor.
    You will be given a competition scenario, previous SOTA and failed experiments and feedbacks, the current SOTA implementation and feedback, and a list of identified problems.
    Your role involves two tasks:
    1. **Hypothesis Proposal**: Propose testable hypotheses to address the identified problems.
    2. **Hypothesis Evaluation**: Evaluate the proposed hypotheses across multiple dimensions.

    # Task 1: Hypothesis Proposal
    For each identified problem, you are required to propose a hypothesis aimed at improving the current SOTA implementation. 
    A hypothesis is a precise, testable, and actionable statement that proposes a specific modification or improvement to address an identified problem in a Kaggle competition implementation.
    {% if not pipeline %}
    Each hypothesis should focus on one of the following 5 components of an implementation:
    {{ component_desc }}
    {% else %}
    Although we don't require each hypothesis to focus on single specific component, you should still respond the main component that the hypothesis focus on.
    Candidate components are:
    {{ component_desc }}
    {% endif %}

    ## Hypothesis Guidelines
    Here are guidelines to aid your hypothesis proposal. You don't need to answer all the questions.
    1. Problem Impact Analysis
      - Assess how the identified problem affects the performance of the current SOTA implementation.
    2. Lessons from Previous Experiments
      - For persistent problem, analyze why previous experiments failed on this problem.
      - Review why previous experiments failed to address the problem. Identify patterns, overlooked factors, or misaligned assumptions.
      - Incorporate learnings from both failed and successful past experiments to ground your hypothesis in evidence.
    3. Actionable Changes
      - If the problem relates to time/memory constraints, suggest smaller model sizes or alternative algorithms with reduced complexity.
      - If the problem involves underperforming models, propose removing or replacing models with significantly worse performance.
      - If the problem relates to hyperparameter tuning, recommend a specific method or strategy for tuning.

    ## Hypothesis Specification
    {{ hypothesis_spec }}


    # Task 2: Hypothesis Evaluation
    After proposing the hypothesis, your second task is to evaluate the hypothesis from multiple dimensions.

    ## Evaluation Instruction
    Please score the proposed hypothesis from 1 to 10 for each of the following dimensions (where 1 means lowest and 10 means highest):
    1. Problem-Hypothesis Alignment: How well the hypothesis addresses the identified problem.
    2. Expected Impact: The estimated improvement after applying the hypothesis to current SOTA implementation.
    3. Novelty: Degree of innovation compared to previous attempts. If the proposed hypothesis is very similar to previous experiments' hypothesis, assign low novelty score.
    4. Feasibility: The ease of implementing the proposed hypothesis in the current SOTA implementation.
    5. Risk-Reward Balance: The exploration-exploitation balance of the proposed hypothesis.

    ## Final Output Format in JSON Schema:
    {{ hypothesis_output_format }}
    
  user: |-
    # Scenario Description
    {{ scenario_desc }}

    # Previous Experiments and Feedbacks:
    {{ exp_and_feedback_list_desc }}

    # Current SOTA Implementation
    {{ sota_exp_desc }}

    # Identified Problems
    {{ problems }}


task_gen:
  system: |-
    {% include "scenarios.data_science.share:scen.role" %}
    The user is improving a Kaggle competition implementation iteratively through traces where each new trace is modified from the current SOTA in the trace, not necessarily the immediate predecessor.
    You will be given a competition scenario, trace history description, the current SOTA implementation, and a proposed hypothesis to improve the current SOTA implementation.
    
    # Step 1: Task Design
    Your first task is to generate new {{ targets }} based on the proposed hypothesis. Your task should very detailed with specific steps and instructions. The task should be specific and fine-grained, avoiding general or vague statements.

    ## Specification
    {{ task_specification }}

    ## Task Design Guidelines
    The task should be concise with several steps each only in a few sentences. 
    DO NOT repeat the details which has already included in the SOTA code. If the SOTA code has covered the steps perfectly, you should not repeat the steps in detail. 
    DO NOT write any code in the task description!
    Observing reasons from failed experiments and feedback to prevent repeating similar mistakes in analogous situations.

    ## [Partial Response Format 1] Task Output Format:
    {{ task_output_format }}

    {% if workflow_check %}
    # Step 2: Workflow Update
    Since components have dependencies, your second task is to update the workflow to reflect the changes made to the target component. Please also decide whether the workflow needs to be updated and provide a brief description of the change task.
    {{ component_desc }}
    [Partial Response Format 2] Your generated workflow description should be a simple text and the following agent will do the implementation. If you think the workflow should not be updated, just respond with "No update needed".
    {% endif %}

    Your final output should strictly adhere to the following JSON format. 
    {
      "task_design": ---The dict corresponding to task output format---,
      {% if workflow_check %}"workflow_update": ---A string corresponding to workflow description--- {% endif %}
    }
    
  user: |-
    # Scenario Description
    {{ scenario_desc }}

    # Current SOTA Implementation
    {{ sota_exp_desc }}

    # Proposed Hypothesis you should strictly follow:
    {{ hypothesis }}

    # Feedback from Previous Failed Experiments (e.g., experiments that did not pass evaluation, encountered bugs, or failed to surpass SOTA performance):
    {{ failed_exp_and_feedback_list_desc }}

specification:
  problem: |-
    1. The problem should be specific and fine-grained. Avoid general or vague statements. 
    2. The problem should technical or methodological. Focus on design and implementation flaws, not runtime errors.
  
  hypothesis: |-
    1. The hypothesis should be precise, testable, and directly actionable. Avoid general or vague statements. For example, "tuning a model" is too broad, whereas "increasing the learning rate to 0.1 in the LightGBM model will improve performance" is specific and actionable.
    2. Each hypothesis should focus on a single direction per experiment. Avoid proposing multiple possibilities within the same hypothesis, such as "this may work in case A or case B." Research and development can be approached at different levels (shallow or deep), but each experimental loop should validate only one specific idea.
    3. The hypothesis should based on current SOTA solution. The user will conduct experiments based on the SOTA solution to test whether the hypothesis improves performance in this specific competition.

output_format:
  problem: |-
    For each of the identified problem, you should strictly adhere to the following JSON schema. 
    Your final output should be a dict containing all the identified problem without anything else.
    Please respond at most five problems considering the most valuable and recently not explored.
    {
      "problem name 1": {
        "problem": "Description of the first issue in no more than three sentences.",
        "reason": "Brief explanation of why this is a problem, based on the feedback or inferred from provided materials in no more than two sentences."
      },
      "problem name 2": {
        "problem": "Description of the second issue in no more than three sentences.",
        "reason": "Brief explanation of why this is a problem, based on the feedback or inferred from provided materials in no more than two sentences."
      }
    }
  hypothesis: |-
    For each of the identified problem, you should propose a hypothesis strictly following to the JSON schema. Your final output should be a dict containing all the proposed hypothesis.
    {
      "problem name 1 (Should be exactly same as the problem name provided)": {
        "reason": "Provide a clear, logical progression from problem identification to hypothesis formulation, grounded in evidence (e.g., trace history, domain principles, or competition constraints). Refer to the Hypothesis Guidelines for better understanding. Reason should be short with no more than two sentences.",
        "component": "The component name that the hypothesis {% if pipeline %}mainly {% endif %}focuses on. Must be one of ('DataLoadSpec', 'FeatureEng', 'Model', 'Ensemble', 'Workflow').",
        "hypothesis": "A concise, testable statement derived from previous experimental outcomes. Limit it to one or two sentences that clearly specify the expected change or improvement in the <component>'s performance.",
        "evaluation": {
          "alignment_score": "The alignment of the proposed hypothesis with the identified problem.",
          "impact_score": "The expected impact of the proposed hypothesis on the current SOTA implementation.",
          "novelty_score": "The novelty of the proposed hypothesis compared to existing solutions.",
          "feasibility_score": "The feasibility of implementing the proposed hypothesis in the current SOTA implementation.",
          "risk_reward_balance_score": "The risk-reward balance of implementing the proposed hypothesis.",
        }
      },
    }
