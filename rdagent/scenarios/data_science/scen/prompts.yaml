scenario_description: |-
  {% if use_raw_description -%}
  ====== Background of the scenario======
  {{ raw_description }}

  {% else %}
  ====== Background of the scenario======
  {{ background }}
  {% endif %}

  {% if eda_output is not none %}The following is the output of the exploratory data analysis (EDA) performed on the dataset, You should carefully analyze it to better craft your feature engineering and model training strategies.
  ====== Data Overview (EDA) ======
  {{ eda_output }}
  {% endif %}

  ====== Submission Format ======
  Please ensure your submission adheres to the following specifications:
  {{ submission_specifications }}

  ====== Important Guidelines ======
  Before submitting your results, please note the following:
  - We have numerous tests in place to check your code.
  - Ensure your submission is genuine.
  - Do not manipulate data or return values solely to pass preliminary tests, as this will not lead to successful final evaluation.

  ====== Evaluation ======
  {% if metric_name %}
  The primary evaluation metric for this task is: **{{ metric_name }}**.
  {% endif %}
  This metric is considered better when it is **{% if metric_direction %}larger{% else %}smaller{% endif %}**.

  {% if evaluation is not none %}
  Additional Evaluation Details:
  {{ evaluation }}
  {% endif %}

  {% if time_limit %}
  ====== Time Limit On Full Code Execution ======
  Your full code's execution is limited to **{{ time_limit }}**. After this time limit, your code will be terminated. But remember your main target is to achieve the best performance and you have several times to modify your code. So please be bold to make the best use of all the time limit and don't be too conservative.
  During this time limit, you have all the resources available to you. Please fully leverage all the computational resources(CPUs and GPUs) to achieve the best performance like choose a powerful model, use a large batch size, enable data sampler with big parallel.
  {% if sample_data_by_LLM is not none and sample_data_by_LLM is true %}
  ====== Time Limit On Debug Mode Code Execution ======
  Your are also required to include a debug mode in your code, the debug code's execution is limited to **{{ debug_time_limit }}**. You should make sure 10 percent of the data training one epoch can be finished within this time limit. If not, your should propose a new debug strategy in your task.
  {% endif %}{% endif %}

competition_description_template:
  system: |-
    You are a data science assistant that extracts structured information from unstructured text.
    The user will provide you a Kaggle competition description, and you need to extract specific details from it.
    If the competition description does not provide enough information, please refer to the Processed Data folder description to make your decisions.
    For the dataset, the competition may not include detailed information about the dataset. The user has read the dataset and provide you the relevant information. Please include it in your response.
    Please answer in Json format with the following schema:
    {
      "Task Type": "The type of competition task, e.g., 'Classification', 'Regression', 'Clustering', 'Recommendation", "Time-Series Forecasting",
      "Data Type": "The type of competition data, e.g., 'Tabular', 'Time Series', 'Text (Natural Language Processing)', 'Image (Computer Vision)', 'Audio', 'Video'", 
      "Brief Description": "A brief description of the competition",
      "Dataset Description": "The dataset utilized in the competition is described based on two sources: the Competition Description, which provides contextual details about the original files, and the Processed Data folder description, which outlines the structure of the dataset after processing. While there may be differences—for instance, original files mentioned in the Competition Description (e.g., .zip files) may have been extracted or restructured—your task is to interpret the new file structure accurately (do not contain any file or folder that is not in Processed Data folder description) and reconcile it with the contextual information from the Competition Description to provide a clear and updated explanation.",
      "Submission Specifications": "The submission specification & sample submission file descriptions for the model to output."
      "Submission channel number to each sample": "The number of channels in the output for each sample, e.g., 1 for regression, N for N class classification with probabilities, etc. A Integer. If not specified, it is 1."
      "Metric Evaluation Description": "A precise explanation of how the submissions are scored in this competition, including how the metric is calculated and any specific considerations.",
      "Metric Name": "The name of the metric which this competition use for scoring the submission."
      "Metric Direction": True or False as True means bigger metric number is better, False means smaller is better.
    }
  user: |-
    Competition Description: 
    {{ competition_raw_description }}

    Processed Data folder description:
    {{ competition_processed_data_folder_description }}
    
    [Note] There may be some discrepancies between the competition description and the processed data folder description. Please base your information on the processed data folder description, particularly the file structure.


competition_background: |-
  You are a world-class data scientist and machine learning engineer with deep expertise in statistics, mathematics, and computer science. 
  Your knowledge spans cutting-edge data analysis techniques, advanced machine learning algorithms, and their practical applications to solve complex real-world problems.
  You are dedicated to producing accurate, efficient, and innovative solutions.

  The task type for this competition is **{{ task_type }}**.
  The data type used in this competition is **{{ data_type }}**.

  Briefly, the competition involves: {{ brief_description }}.
  
  The dataset used in this competition is:
  {{ dataset_description }}.
  
  Submission channel number to each sample is: {{ model_output_channel }}.

  The evaluation metric of this competition is:
  {{ metric_description }}.

rich_style_description: |-
  ### {{ name }} Agent: Automated Feature Engineering & Model Tuning Evolution

  #### [Overview](#_summary)

  In this scenario, our automated system proposes hypothesis, choose action, implements code, conducts validation, and utilizes feedback in a continuous, iterative process.

  #### {{ name }} Competition info

  Current Competition: {{ competition }}

  #### [Automated R&D](#_rdloops)

  - **[R (Research)](#_research)**
  - Iteration of ideas and hypotheses.
  - Continuous learning and knowledge construction.

  - **[D (Development)](#_development)**
  - Evolving code generation, model refinement, and features generation.
  - Automated implementation and testing of models/features.

  #### [Objective](#_summary)

  To automatically optimize performance metrics within the validation set, ultimately discovering the most efficient features and models through autonomous research and development.
