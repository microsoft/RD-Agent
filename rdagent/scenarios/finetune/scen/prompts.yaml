scenario_description: |-
  The user is targeting a fine-tuned model best for specific scenarios based on the provided dataset.
  The user has decided to fine-tune the model using LLaMA-Factory framework. Make sure your hypothesis and task align with LLaMA-Factory's capabilities and best practices.

  # User objectives
  By Fine-tuning the model, the user aims to achieve the following objectives:
  {% if user_target_scenario is not none %}
  The user described their target scenario as: {{ user_target_scenario }}
  {% endif %}
  {% if target_benchmark is not none and benchmark_description is not none %}
  The user aims to excel in the following benchmark(s): {{ target_benchmark }}.
  The benchmark can be described as: {{ benchmark_description }}.
  {% endif %}

  # Device Information
  The device available for fine-tuning has the following specifications:
  {{ device_info }}
  The hardware constraints might limit certain choices, so consider them carefully.

  {% if chosen_model %}
  # Base Model Details
  The user has decided the base model to fine-tune: {{ base_model }}.
  ## Model Details
  {{ model_info }}
  {% else %}
  The user has not yet decided the base model to fine-tune.
  {% endif %}

  {% if enable_dataset_description %}
  # Provided Dataset Details
  {{ dataset_info }}
  The dataset characteristics is provided for you to understand the data better. Each dataset is a folder of files. Some in good format for fine-tuning while some are not.

  ## Dataset info json
  {{ data_info_json }}

  ## Timeout Constraints
  - Debug Timeout: {{ debug_timeout }}
  - Full Training Timeout: {{ full_timeout }}
  {% endif %}
  
dataset_classification:
  system: |-
    Analyze datasets and classify them by task type.

    ## Task Types (Use EXACTLY these category names)
    - math: Mathematical reasoning, calculation, proofs, arithmetic
    - code: Code generation, completion, debugging, programming
    - finance: Financial analysis, trading, economics, investment
    - healthcare: Medical, health, biology, clinical data
    - legal: Law, regulations, contracts, legal documents
    - agriculture: Farming, crops, livestock, agricultural science
    - literature: Writing, stories, poetry, literary analysis
    - general: General QA, chat, instruction following, common knowledge

    ## Analysis Guidelines
    1. Examine column names, sample content, and README files
    2. Look for keywords in dataset names and descriptions
    3. If a dataset spans multiple domains, choose the PRIMARY focus
    4. The path should be the most outer directory path of the dataset.

    ## Output Format
    ```json
    {
      "math": ["dataset_1_path", "dataset_2_path"],
      "code": ["dataset_3_path"],
      "general": ["dataset_4_path"]
    }
    ```

    **Rules**:
    - Use EXACT dataset names from the folder structure
    - Use ONLY the predefined category names above
    - Each dataset belongs to exactly ONE category
    - Only include categories that have at least one dataset

  user: |-
    Analyze and classify these datasets:
    ```
    {{ dataset_info }}
    ```

dataset_info_generation:
  system: |-
    Generate a LLaMA-Factory dataset_info.json configuration entry.

    ## Format Types:
    **Alpaca**: instruction-response data with "instruction", "input", "output" fields
    **ShareGPT**: conversational data with message arrays

    ## Required Fields:
    - `file_name`: relative path from datasets directory
    - `formatting`: "alpaca" (default) or "sharegpt"  
    - `columns`: map data fields to LLaMA-Factory expected names

    ## Common Column Mappings:
    - Alpaca: "instruction"→prompt, "input"→query, "output"→response
    - ShareGPT: "conversations"→messages, plus role/content tags
    
    ## Dataset Selection
    {% if target_dataset_list|length == 0 %}
    Generate configuration for all datasets found in the datasets directory.
    {% else %}
    The user only focus on certain dataset(s).
    Generate configuration for the following dataset(s): {{ target_dataset_list }}.
    {% endif %}

    ## Specific Instructions
    - The outer key must be the dataset name (preserve "/" exactly). For example, "my_dataset" or "chat/dataset".
    - For `file_name`, provide the relative path from the original directory to the data files. Mostly it is under "dataset_name/...".
    - Choose "alpaca" or "sharegpt" based on data structure.
    - Map column names from sample data to LLaMA-Factory format.
    - For datasets not following Alpaca or ShareGPT format. Please choose the closest one and adjust column mappings accordingly.
    - The folder might contain multiple files also multiple datasets. Please include all valid datasets you can find in your response.

    ## Examples:
    ```json
    {
      "my_dataset": {
        "file_name": "my_dataset/train.json",
        "columns": {"prompt": "instruction", "response": "output"}
      },
      "chat_dataset": {
        "file_name": "chat_dataset/data.json",
        "formatting": "sharegpt",
        "columns": {"messages": "conversations"}
      }
    }
    ```

    **Output Format**:
    ```json
    {
      "dataset_name": {
        "file_name": "dataset_name/...",
        "formatting": "alpaca|sharegpt",
        "columns": {...}
      }
    }
    ```

  user: |-
    **Dataset folder description**:
    ```
    {{ dataset_info }}
    ```
