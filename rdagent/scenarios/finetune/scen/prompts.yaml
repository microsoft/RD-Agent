scenario_description: |-
  The user is targeting a fine-tuned model best for specific scenarios based on the provided dataset.
  The user has decided to fine-tune the model using LLaMA-Factory framework. Make sure your hypothesis and task align with LLaMA-Factory's capabilities and best practices.

  By Fine-tuning the model, the user aims to achieve the following objectives:
  {% if intention is not none %}
  The user described their intention as: {{ intention }}
  {% endif %}
  {% if target_benchmark is not none %}
  The user aims to excel in the following benchmark(s): {{ target_benchmark }}.
  The benchmark can be described as: {{ benchmark_info }}.
  {% endif %}

  The device available for fine-tuning has the following specifications:
  {{ device_info }}
  The hardware constraints might limit certain choices, so consider them carefully.

  {% if chosen_model %}
  The user has decided the base model to fine-tune: {{ base_model }}.
  ## Model Details
  {{ model_info }}
  {% else %}
  The user has not yet decided the base model to fine-tune.
  {% endif %}

  ## Provided Dataset Details
  {{ dataset_info }}
  The dataset characteristics is provided for you to understand the data better. Each dataset is a folder of files. Some in good format for fine-tuning while some are not.

  ## Dataset info json
  {{ data_info_json }}

  ## Timeout Constraints
  - Debug Timeout: {{ debug_timeout }}
  - Full Training Timeout: {{ full_timeout }}

dataset_info_generation:
  system: |-
    Generate a LLaMA-Factory dataset_info.json configuration entry.

    ## Format Types:
    **Alpaca**: instruction-response data with "instruction", "input", "output" fields
    **ShareGPT**: conversational data with message arrays

    ## Required Fields:
    - `file_name`: relative path from datasets directory
    - `formatting`: "alpaca" (default) or "sharegpt"  
    - `columns`: map data fields to LLaMA-Factory expected names

    ## Common Column Mappings:
    - Alpaca: "instruction"→prompt, "input"→query, "output"→response
    - ShareGPT: "conversations"→messages, plus role/content tags
    
    ## Dataset Selection
    {% if target_dataset_list|length == 0 %}
    Generate configuration for all datasets found in the datasets directory.
    {% else %}
    The user only focus on certain dataset(s).
    Generate configuration for the following dataset(s): {{ target_dataset_list }}.
    {% endif %}

    ## Specific Instructions
    - The outer key must be the dataset name (preserve "/" exactly). For example, "my_dataset" or "chat/dataset".
    - For `file_name`, provide the relative path from the original directory to the data files. Mostly it is under "dataset_name/...".
    - Choose "alpaca" or "sharegpt" based on data structure.
    - Map column names from sample data to LLaMA-Factory format.
    - For datasets not following Alpaca or ShareGPT format. Please choose the closest one and adjust column mappings accordingly.
    - The folder might contain multiple files also multiple datasets. Please include all valid datasets you can find in your response.

    ## Examples:
    ```json
    {
      "my_dataset": {
        "file_name": "my_dataset/train.json",
        "columns": {"prompt": "instruction", "response": "output"}
      },
      "chat_dataset": {
        "file_name": "chat_dataset/data.json",
        "formatting": "sharegpt",
        "columns": {"messages": "conversations"}
      }
    }
    ```

    **Output Format**:
    ```json
    {
      "dataset_name": {
        "file_name": "dataset_name/...",
        "formatting": "alpaca|sharegpt",
        "columns": {...}
      }
    }
    ```

  user: |-
    **Dataset folder description**:
    ```
    {{ dataset_info }}
    ```
