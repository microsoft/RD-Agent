scenario_description: |-
  The user is targeting a fine-tuned model best for specific scenarios based on the provided dataset.
  The user has decided to fine-tune the model using LLaMA-Factory framework. Make sure your hypothesis and task align with LLaMA-Factory's capabilities and best practices.

  # User objectives
  By Fine-tuning the model, the user aims to achieve the following objectives:
  {% if user_target_scenario is not none %}
  The user described their target scenario as: {{ user_target_scenario }}
  {% endif %}
  {% if target_benchmark is not none and benchmark_description is not none %}
  The user aims to excel in the following benchmark(s): {{ target_benchmark }}.
  The benchmark can be described as: {{ benchmark_description }}.
  {% endif %}

  # Device Information
  The device available for fine-tuning has the following specifications:
  {{ device_info }}
  The hardware constraints might limit certain choices, so consider them carefully.

  {% if chosen_model %}
  # Base Model Details
  The user has decided the base model to fine-tune: {{ base_model }}.
  ## Model Details
  {{ model_info }}
  {% else %}
  The user has not yet decided the base model to fine-tune.
  {% endif %}

  {% if enable_dataset_description %}
  # Provided Dataset Details
  {{ dataset_info }}
  The dataset characteristics is provided for you to understand the data better. Each dataset is a folder of files. Some in good format for fine-tuning while some are not.

  ## Dataset info json
  {{ data_info_json }}

  ## Timeout Constraints
  - Debug Timeout: {{ debug_timeout }}
  - Full Training Timeout: {{ full_timeout }}
  {% endif %}
  
dataset_info_generation:
  system: |-
    Generate a LLaMA-Factory dataset_info.json configuration entry with category classification.

    ## Format Types:
    **Alpaca**: instruction-response data with "instruction", "input", "output" fields
    **ShareGPT**: conversational data with message arrays

    ## Required Fields:
    - `file_name`: relative path from datasets directory
    - `formatting`: "alpaca" (default) or "sharegpt"  
    - `columns`: map data fields to LLaMA-Factory expected names
    - `category`: list of domain categories (can be one or multiple, see below)

    ## Category Classification
    Analyze each dataset and classify it by domain. A dataset can belong to **one or multiple** domains. Use one or more of these category names:
    
    - **physics**: Physics, mechanics, thermodynamics, quantum mechanics, electromagnetism, optics
    - **math**: Mathematics, algebra, geometry, calculus, statistics, logic, mathematical reasoning
    - **chemistry**: Chemistry, organic chemistry, inorganic chemistry, biochemistry, molecular structures
    - **biology**: Biology, genetics, ecology, microbiology, cell biology, evolution, physiology
    - **table**: Tabular data, spreadsheets, structured data analysis, data tables, CSV/Excel data
    - **legal**: Law, regulations, contracts, legal documents, court cases, legislation
    - **medicine**: Medicine, clinical data, medical diagnosis, pharmaceuticals, healthcare, patient care
    - **finance**: Finance, trading, economics, investment, markets, banking, financial analysis
    
    **Classification Guidelines:**
    - Examine column names, sample content, and README files carefully
    - Look for domain-specific keywords in dataset names and descriptions
    - **A dataset can have multiple categories** if it covers multiple domains (e.g., biophysics → ["biology", "physics"])
    - List ALL applicable domains, ordered by relevance (most relevant first)
    - For datasets with structured tabular data format, include "table" along with the content domain


    ## Common Column Mappings:
    - Alpaca: "instruction"→prompt, "input"→query, "output"→response
    - ShareGPT: "conversations"→messages, plus role/content tags
    
    ## Dataset Selection
    {% if target_dataset_list|length == 0 %}
    Generate configuration for all datasets found in the datasets directory.
    {% else %}
    The user only focus on certain dataset(s).
    Generate configuration for the following dataset(s): {{ target_dataset_list }}.
    {% endif %}

    ## Specific Instructions
    - The outer key must be the dataset name (preserve "/" exactly). For example, "my_dataset" or "chat/dataset".
    - For `file_name`, provide the relative path from the original directory to the data files. Mostly it is under "dataset_name/...".
    - Choose "alpaca" or "sharegpt" based on data structure.
    - Map column names from sample data to LLaMA-Factory format.
    - Assign appropriate `category` array based on dataset content analysis:
      - Single domain: `["math"]`
      - Multiple domains: `["physics", "math"]` (ordered by relevance)
      - Include "table" if the dataset is in tabular format
    - For datasets not following Alpaca or ShareGPT format. Please choose the closest one and adjust column mappings accordingly.
    - The folder might contain multiple files also multiple datasets. Please include all valid datasets you can find in your response.

    ## Examples:
    ```json
    {
      "my_dataset": {
        "file_name": "my_dataset/train.json",
        "columns": {"prompt": "instruction", "response": "output"},
        "category": ["math"]
      },
      "chat_dataset": {
        "file_name": "chat_dataset/data.json",
        "formatting": "sharegpt",
        "columns": {"messages": "conversations"}
        "category": ["math","code"]
      }
    }
    ```

    **Output Format**:
    ```json
    {
      "dataset_name": {
        "file_name": "dataset_name/...",
        "formatting": "alpaca|sharegpt",
        "columns": {...},
        "category": ["domain1", "domain2", ...]
      }
    }
    ```

  user: |-
    **Dataset folder description**:
    ```
    {{ dataset_info }}
    ```
