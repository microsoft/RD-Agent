# Data format conversion task description template
data_format_task_prompt: |-
  # Data Format Conversion Task

  ## Objective
  Convert dataset `{{ dataset }}` to LLaMA-Factory compatible format and save to appropriate location.

  ## Current Runtime Environment
  ```
  {{ runtime_info }}
  ```

  ## Dataset Samples
  Here are the first few samples from the dataset:
  ```json
  {{ data_samples }}
  ```

  ## LLaMA-Factory Data Format Requirements

  ### Alpaca Format (Recommended)
  ```json
  [
    {
      "instruction": "User instruction",
      "input": "Input content (optional)", 
      "output": "Expected output"
    }
  ]
  ```

  ### ShareGPT Format
  ```json
  [
    {
      "conversations": [
        {"from": "human", "value": "User message"},
        {"from": "gpt", "value": "Assistant reply"}
      ]
    }
  ]
  ```

  ## Task Requirements

  1. **Load Dataset**: Load dataset from `/workspace/llm_finetune/data/raw/{{ dataset }}/` (Docker mounted path)
  2. **Analyze Original Data Format**: Identify the field structure of the dataset
  3. **Choose Appropriate Format**: Select Alpaca or ShareGPT format based on data characteristics
  4. **Data Conversion**: Write Python code for format conversion
  5. **Save Data**: Save processed data as `/workspace/llm_finetune/data/processed_dataset.json`
  6. **Create Configuration**: Create dataset_info.json configuration file in LLaMA Factory format
  7. **Data Statistics**: Output statistics before and after processing

  ## Important Notes
  - **Always use Docker mounted paths**: `/workspace/llm_finetune/data/raw/{{ dataset }}/` for input data
  - **Do not use local filesystem paths**: Avoid paths like `/home/` or absolute local paths
  - **Check mounted data availability**: Verify dataset files exist in mounted location first

  ## Output Files
  - `/workspace/llm_finetune/shared/processed_dataset.json`: Processed training data
  - `/workspace/llm_finetune/shared/dataset_info.json`: Dataset configuration file in LLaMA Factory format
  - Also copy files to `/workspace/llm_finetune/data/` for backward compatibility
  - Output data processing statistics to console

  ## LLaMA Factory dataset_info.json Format
  **CRITICAL**: The dataset_info.json must follow this exact format:
  ```json
  {
    "processed_dataset": {
      "file_name": "processed_dataset.json",
      "columns": {
        "prompt": "instruction",
        "query": "input", 
        "response": "output"
      }
    }
  }
  ```

  Please write a complete Python script to accomplish the above tasks.

# Data format conversion conversation prompts (system first, then user)
data_format_system_prompt: |-
  You are a data processing expert. You need to write a Python script based on user requirements to process datasets
  and convert them to LLaMA-Factory compatible format.

  Please ensure:
  1. Code can run directly
  2. All necessary imports are included
  3. Proper error handling
  4. Clear logging output
  5. Save files to specified paths

data_format_user_prompt: |-
  Please generate a complete Python script (main.py) based on the following task description:

  {{ task_description }}

  Output format:
  ```python
  # main.py - Data processing script
  [Complete Python code]
  ```
