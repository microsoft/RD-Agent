# Data format conversion task description template
data_format_task_prompt: |-
  # Data Format Conversion Task

  ## Objective
  Convert dataset `{{ dataset }}` to LLaMA-Factory compatible format and save to appropriate location.

  ## Current Runtime Environment
  ```
  {{ runtime_info }}
  ```

  ## Dataset Samples
  Here are the first few samples from the dataset:
  ```json
  {{ data_samples }}
  ```

  ## LLaMA-Factory Data Format Requirements

  ### Alpaca Format (Recommended)
  ```json
  [
    {
      "instruction": "User instruction",
      "input": "Input content (optional)", 
      "output": "Expected output"
    }
  ]
  ```

  ### ShareGPT Format
  ```json
  [
    {
      "conversations": [
        {"from": "human", "value": "User message"},
        {"from": "gpt", "value": "Assistant reply"}
      ]
    }
  ]
  ```

  ## Task Requirements

  1. **Load Dataset**: Load dataset from `/data/dataset/{{ dataset }}/` (Docker mounted path)
  2. **Analyze Original Data Format**: Identify the field structure of the dataset
  3. **Choose Appropriate Format**: Select Alpaca or ShareGPT format based on data characteristics
  4. **Data Conversion**: Write Python code for format conversion
  5. **Save Data**: Save processed data as `/workspace/data/processed_dataset.json`
  6. **Create Configuration**: Create dataset_info.json configuration file in LLaMA Factory format
  7. **Data Statistics**: Output statistics before and after processing

  ## Important Notes
  - **Always use Docker mounted paths**: `/data/dataset/{{ dataset }}/` for input data
  - **Do not use local filesystem paths**: Avoid paths like `/home/` or absolute local paths
  - **Check mounted data availability**: Verify dataset files exist in mounted location first
  - **Create output directory**: Ensure `/workspace/data/` directory exists before saving files

  ## Output Files
  - `/workspace/data/processed_dataset.json`: Processed training data
  - `/workspace/data/dataset_info.json`: Dataset configuration file in LLaMA Factory format
  - Output data processing statistics to console

  ## LLaMA Factory dataset_info.json Format
  **CRITICAL**: The dataset_info.json must follow this exact format:
  ```json
  {
    "processed_dataset": {
      "file_name": "processed_dataset.json",
      "columns": {
        "prompt": "instruction",
        "query": "input", 
        "response": "output"
      }
    }
  }
  ```

  Please write a complete Python script to accomplish the above tasks.

# Data format conversion conversation prompts (system first, then user)
data_format_system_prompt: |-
  You are a data processing expert. You need to write a Python script based on user requirements to process datasets
  and convert them to LLaMA-Factory compatible format.

  IMPORTANT: Return ONLY valid Python code without any markdown formatting, explanations, or comments outside the code.
  Do not use markdown code blocks (```python), bullet points (â€¢), or any non-ASCII characters in comments.

  Please ensure:
  1. Code can run directly without additional modifications
  2. All necessary imports are included at the beginning
  3. Proper error handling with try-except blocks
  4. Clear logging output using print statements
  5. Save files to specified paths in the Docker container
  6. The script should be self-contained and runnable as main.py
  7. Use only ASCII characters in all comments and strings
