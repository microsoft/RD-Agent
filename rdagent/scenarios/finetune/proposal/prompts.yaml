hypothesis_gen:
  system_prompt: |-
    You are an expert in LLM fine-tuning. Your task is to select the optimal configuration based on hardware constraints and dataset characteristics.

    ## Task
    {% if specified_model %}
    Select the optimal fine-tuning method and quantization strategy for the specified model.
    {% else %}
    Select the optimal combination of base model, fine-tuning method, and quantization strategy.
    {% endif %}

    ## Available Options

    {% if not specified_model %}
    **Available Models** (showing first 10):
    {{ available_models }}
    {% endif %}

    **Fine-tuning Methods**:
    {{ available_methods }}

    **Quantization Options**:
    - none: No quantization (highest quality, most memory usage)
    - 4bit: 4-bit quantization (good balance of quality and memory)
    - 8bit: 8-bit quantization (memory efficient)

    ## Selection Criteria
    1. **Memory Constraints**: Consider GPU memory size to choose appropriate model size and quantization
    2. **Task Requirements**: Select fine-tuning method based on dataset characteristics
    3. **Quality Balance**: Achieve best performance within resource constraints

    ## Output Format
    Respond in JSON format:
    {% if specified_model %}
    {
      "model": "{{ specified_model }}",
      "method": "fine-tuning method",
      "quantization": "quantization type"
    }
    Note: The model is already specified as {{ specified_model }}, only select the optimal method and quantization.
    {% else %}
    {
      "model": "model_name",
      "method": "fine-tuning method",
      "quantization": "quantization type"
    }
    {% endif %}

  user_prompt: |-
    ## Hardware Information
    - GPU Memory: {{ memory_gb }}GB
    - GPU Name: {{ gpu_name }}
    - GPU Number: {{ gpu_count }}

    ## Dataset Information
    - Name: {{ dataset_name }}
    - Sample: {{ first_sample }}
    - Sample Count: {{ dataset_sample_count }} samples
    - Total Size: {{ dataset_total_size_mb }} MB

    {% if trace.hist %}
    ## Historical Experiments

    {% for experiment, feedback in trace.hist[-5:] %}
    ### Experiment {{ loop.index }}
    {% if experiment.hypothesis %}
    - Configuration: Model={{ experiment.hypothesis.base_model }}, Method={{ experiment.hypothesis.finetune_method }}, Quantization={{ experiment.hypothesis.quantization }}
    - Hypothesis: {{ experiment.hypothesis.hypothesis }}
    {% endif %}
    - Result: {{ "✅ Successful" if feedback.decision else "❌ Failed" }}
    {% if feedback.observations %}
    - Observations: {{ feedback.observations[:300] }}
    {% endif %}
    {% if feedback.reason %}
    - Reason: {{ feedback.reason[:200] }}
    {% endif %}

    {% endfor %}

    **Task**: Based on the historical results above, select a NEW configuration that:
    1. Avoids failed configurations and learns from their mistakes
    2. Builds upon successful configurations to improve performance
    3. Explores promising directions not yet tested
    {% else %}
    **Task**: This is the first experiment. Select the optimal configuration based on hardware and dataset characteristics.
    {% endif %}

    {% if specified_model %}
    ## Specified Model
    {{ specified_model }}

    Please select the optimal fine-tuning method and quantization strategy for this model.
    {% else %}
    Please select the optimal combination of model, fine-tuning method, and quantization strategy.
    {% endif %}