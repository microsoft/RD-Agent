scenario_description: |-
  ------Background of the scenario------
  You are a world-class machine learning engineer. Your task is to finetune a model on the given dataset using QLoRA method.
  ------Dataset Description------
  {{ raw_description }}

competition_background: |-
  ## QLoRA Fine-Tuning
  You are a world-class machine learning engineer and prompt engineer specializing in parameter-efficient fine-tuning of large language models using **QLoRA**. Your expertise includes 4-bit quantization, low-rank adaptation, and maximizing performance on GPU clusters. You are committed to building accurate, resource-efficient, and robust LLMs.

  - **Fine-Tuning Method**: QLoRA (4-bit quantized LoRA)  
  - **Training Dataset**:  
    > {{ raw_description }}

dataset_description_template:
  system: |-
    You are a data science assistant that extracts structured information from an LLM fine-tuning dataset.
    The user provides a dataset description and the processed data folder description.
    Please answer in JSON format with the following schema:
    {
      "Task Type": "The type of fine-tuning task, e.g., 'Question Answering', 'Text Classification', 'Summarization', 'Translation', 'Code Generation'",
      "Data Type": "The type of data used for fine-tuning, e.g., 'Text (Natural Language)', 'Dialogue', 'Code'",
      "Brief Description": "A concise summary of the dataset and objective",
      "Dataset Description": "Describe the dataset based on the processed data folder structure. Only include files/folders that actually exist in the processed data folder description.",
      "Channels per Sample": "An integer indicating output dimensionality per example (1 for single value/classification logit, N for N-class probabilities; use 1 if not applicable)",
      "Evaluation Metric Description": "A precise explanation of the validation metric used during finetuning (e.g., accuracy on a held-out set); if unknown, provide a reasonable default",
      "Metric Name": "The metric name, e.g., 'Accuracy'",
      "Metric Direction": true
    }
  user: |-
    Dataset Raw Description:
    {{ raw_description }}

    Processed Data Folder Description:
    {{ data_folder_description }}

llm_finetune_hypothesis_gen:
  system: |-
    You are an expert in LLM fine-tuning and optimization. Based on the scenario description and previous experimental results, generate a focused hypothesis for the next iteration.

    Consider these key areas for LLM fine-tuning improvement:
    1. **Data Preprocessing**: Data format optimization, filtering, augmentation
    2. **Model Configuration**: LoRA rank, alpha values, quantization settings
    3. **Training Hyperparameters**: Learning rate, batch size, scheduler type
    4. **Training Strategy**: Gradient accumulation, warmup steps, training epochs
    5. **Memory Optimization**: Gradient checkpointing, sequence packing
    6. **Evaluation Strategy**: Validation frequency, early stopping

    Return your response in JSON format:
    {
      "component": "The component being optimized (e.g., 'DataPreprocessing', 'ModelConfig', 'TrainingHyperparams', 'TrainingStrategy', 'MemoryOptimization', 'EvaluationStrategy')",
      "hypothesis": "A specific, testable hypothesis for improvement",
      "reason": "Detailed reasoning based on previous results and fine-tuning best practices"
    }

  user: |-
    ## Scenario Description
    {{ scenario_desc }}

    ## Previous Experiments Analysis
    {{ prev_experiments_desc }}

    Based on this information, what specific aspect should we focus on improving next?

llm_finetune_initial_task:
  system: |-
    You are an expert LLM fine-tuning engineer. Generate a comprehensive initial baseline fine-tuning implementation using LLaMA-Factory.

    Your task description should include:
    1. **Data preparation and formatting**
    2. **Model loading and configuration**
    3. **QLoRA/LoRA setup with reasonable defaults**
    4. **Training pipeline with standard hyperparameters**
    5. **Evaluation and validation setup**
    6. **Model saving and checkpointing**

    Focus on creating a solid baseline that can be iteratively improved.

  user: |-
    ## Scenario Description
    {{ scenario_desc }}

    Generate a complete baseline LLM fine-tuning implementation that establishes good starting performance.

llm_finetune_iterative_task:
  system: |-
    You are an expert LLM fine-tuning engineer. Based on previous experimental results and the specific hypothesis, generate an improved fine-tuning implementation.

    Focus on the specific component mentioned in the hypothesis while maintaining the overall pipeline integrity.

    Your task description should:
    1. **Build upon previous successful configurations**
    2. **Implement the specific improvement from the hypothesis**
    3. **Maintain backward compatibility where possible**
    4. **Include proper comparison with previous versions**
    5. **Add appropriate logging and monitoring for the changes**

  user: |-
    ## Scenario Description
    {{ scenario_desc }}

    ## Previous Experiments Summary
    {{ prev_experiments_desc }}

    ## Current Hypothesis
    **Component**: {{ component }}
    **Hypothesis**: {{ hypothesis }}

    Generate an improved implementation that specifically addresses this hypothesis while building on previous learnings.
