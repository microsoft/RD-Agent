{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1830cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from proposal import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trace(Generic[ASpecificScen, ASpecificKB]):\n",
    "    NodeType = tuple[Experiment, ExperimentFeedback]  # Define NodeType as a new type representing the tuple\n",
    "    NEW_ROOT: tuple = ()\n",
    "\n",
    "    def __init__(self, scen: ASpecificScen, knowledge_base: ASpecificKB | None = None) -> None:\n",
    "        self.scen: ASpecificScen = scen\n",
    "\n",
    "        # BEGIN: graph structure -------------------------\n",
    "        self.hist: list[Trace.NodeType] = (\n",
    "            []\n",
    "        )  # List of tuples containing experiments and their feedback, organized over time.\n",
    "        self.dag_parent: list[tuple[int, ...]] = []  # List of tuples representing parent indices in the DAG structure.\n",
    "        # Definition:\n",
    "        # - (,) represents no parent (root node in one tree);\n",
    "        # - (1,) presents one parent;\n",
    "        # - (1, 2) represents two parents (Multiple parent is not implemented yet).\n",
    "        # Syntax sugar for the parent relationship:\n",
    "        # - Only for selection:\n",
    "        #    - (-1,) indicates that select the last record node as parent.\n",
    "\n",
    "        # NOTE: the sequence of hist and dag_parent is organized by the order to record the experiment.\n",
    "        # So it may be different from the order of the loop_id.\n",
    "        # So we need an extra mapping to map the enqueue id back to the loop id.\n",
    "        self.idx2loop_id: dict[int, int] = {}\n",
    "\n",
    "        # Design discussion:\n",
    "        # - If we unifiy the loop_id and the enqueue id, we will have less recognition burden.\n",
    "        # - If we use different id for loop and enqueue, we don't have to handle the placeholder logic.\n",
    "        # END: graph structure -------------------------\n",
    "\n",
    "        # TODO: self.hist is 2-tuple now, remove hypothesis from it, change old code for this later.\n",
    "        self.knowledge_base: ASpecificKB | None = knowledge_base\n",
    "        self.current_selection: tuple[int, ...] = (-1,)\n",
    "\n",
    "    def get_sota_hypothesis_and_experiment(self) -> tuple[Hypothesis | None, Experiment | None]:\n",
    "        \"\"\"Access the last experiment result, sub-task, and the corresponding hypothesis.\"\"\"\n",
    "        # TODO: The return value does not align with the signature.\n",
    "        for experiment, feedback in self.hist[::-1]:\n",
    "            if feedback.decision:\n",
    "                return experiment.hypothesis, experiment\n",
    "\n",
    "        return None, None\n",
    "\n",
    "    def is_selection_new_tree(self, selection: tuple[int, ...] | None = None) -> bool:\n",
    "        \"\"\"\n",
    "        Check if the current trace is a new tree.\n",
    "        - selection maybe (-1,) when the dag_parent is empty.\n",
    "        \"\"\"\n",
    "        if selection is None:\n",
    "            selection = self.get_current_selection()\n",
    "\n",
    "        return selection == self.NEW_ROOT or len(self.dag_parent) == 0\n",
    "\n",
    "    def get_current_selection(self) -> tuple[int, ...]:\n",
    "        return self.current_selection\n",
    "\n",
    "    def set_current_selection(self, selection: tuple[int, ...]) -> None:\n",
    "        self.current_selection = selection\n",
    "\n",
    "    def get_parent_exps(\n",
    "        self,\n",
    "        selection: tuple[int, ...] | None = None,\n",
    "    ) -> list[Trace.NodeType]:\n",
    "        \"\"\"\n",
    "        Collect all ancestors of the given selection.\n",
    "        The return list follows the order of [root->...->parent->current_node].\n",
    "        \"\"\"\n",
    "        if selection is None:\n",
    "            selection = self.get_current_selection()\n",
    "\n",
    "        if self.is_selection_new_tree(selection):\n",
    "            return []\n",
    "\n",
    "        return [self.hist[i] for i in self.get_parents(selection[0])]\n",
    "\n",
    "    def exp2idx(self, exp: Experiment | list[Experiment]) -> int | list[int] | None:\n",
    "        if isinstance(exp, list):\n",
    "            exps: list[Experiment] = exp\n",
    "\n",
    "            # keep the order\n",
    "            exp_to_index: dict[Experiment, int] = {_exp: i for i, (_exp, _) in enumerate(self.hist)}\n",
    "            return [exp_to_index[_exp] for _exp in exps]\n",
    "        for i, (_exp, _) in enumerate(self.hist):\n",
    "            if _exp == exp:\n",
    "                return i\n",
    "        return None\n",
    "\n",
    "    def idx2exp(self, idx: int | list[int]) -> Experiment | list[Experiment]:\n",
    "        if isinstance(idx, list):\n",
    "            idxs: list[int] = idx\n",
    "            return [self.hist[_idx][0] for _idx in idxs]\n",
    "        return self.hist[idx][0]\n",
    "\n",
    "    def is_parent(self, parent_idx: int, child_idx: int) -> bool:\n",
    "        ancestors = self.get_parents(child_idx)\n",
    "        return parent_idx in ancestors\n",
    "\n",
    "    def get_parents(self, child_idx: int) -> list[int]:\n",
    "        if self.is_selection_new_tree((child_idx,)):\n",
    "            return []\n",
    "\n",
    "        ancestors: list[int] = []\n",
    "        curr = child_idx\n",
    "        while True:\n",
    "            ancestors.insert(0, curr)\n",
    "            parent_tuple = self.dag_parent[curr]\n",
    "            if not parent_tuple or parent_tuple[0] == curr:\n",
    "                break\n",
    "            curr = parent_tuple[0]\n",
    "\n",
    "        return ancestors\n",
    "    \n",
    "    def get_reply_tree_dict(self) -> dict[int, dict]:\n",
    "        tree_dict: dict[int, dict] = {}\n",
    "        for idx, (experiment, feedback) in enumerate(self.hist):\n",
    "            tree_dict[idx] = {\n",
    "                'hypothesis': experiment.hypothesis,\n",
    "                'feedback': feedback.decision,\n",
    "                'children': []\n",
    "            }\n",
    "        for child_idx, parents in enumerate(self.dag_parent):\n",
    "            for parent_idx in parents:\n",
    "                if parent_idx != child_idx:  \n",
    "                    tree_dict[parent_idx]['children'].append(child_idx)\n",
    "\n",
    "        return tree_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fef5764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/userdata/v-lijingyuan/anaconda3/envs/rdagent/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/data/userdata/v-lijingyuan/anaconda3/envs/rdagent/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from rdagent.log.storage import FileStorage\n",
    "from pathlib import Path\n",
    "from rdagent.scenarios.data_science.experiment.experiment import DSExperiment\n",
    "\n",
    "from rdagent.log.utils import extract_loopid_func_name\n",
    "log_path = Path(\"/home/bowen/workspace/JobAndExp/amlt_project/amlt/dynamic-prawn/combined_logs/aerial-cactus-identification.1\")\n",
    "\n",
    "traces = []\n",
    "for msg in FileStorage(log_path).iter_msg(tag=\"trace\"):\n",
    "    loop_id, fn = extract_loopid_func_name(msg.tag)\n",
    "    traces.append(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c86a1c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tr = traces[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c87a2013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Tr.hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78f8231b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tr.current_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9ab29cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DSTrace' object has no attribute 'idx2loop_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mTr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midx2loop_id\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DSTrace' object has no attribute 'idx2loop_id'"
     ]
    }
   ],
   "source": [
    "Tr.idx2loop_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b114c2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tr.idx2loop_id[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c11c1be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<rdagent.scenarios.data_science.experiment.experiment.DSExperiment at 0x7f4924407850>,\n",
       " <rdagent.core.proposal.HypothesisFeedback at 0x7f4924407d30>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tr.hist[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ee9b90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tr.get_current_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c300a40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<rdagent.scenarios.data_science.experiment.experiment.DSExperiment at 0x7f684ce421a0>,\n",
       " <rdagent.core.proposal.HypothesisFeedback at 0x7f684ce42680>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tr.hist[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2e77aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tr.exp2idx(Tr.hist[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b60ddd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DSTrace' object has no attribute 'idx2loop_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mTr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midx2loop_id\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DSTrace' object has no attribute 'idx2loop_id'"
     ]
    }
   ],
   "source": [
    "Tr.idx2loop_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc1a53b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dict: dict[int, dict] = {}        \n",
    "for idx, (experiment, feedback) in enumerate(Tr.hist):\n",
    "    tree_dict[idx] = {\n",
    "                'hypothesis': experiment.hypothesis.hypothesis,\n",
    "                'feedback': feedback.decision,\n",
    "                'children': []\n",
    "            }\n",
    "for child_idx, parents in enumerate(Tr.dag_parent):\n",
    "    for parent_idx in parents:\n",
    "        if parent_idx != child_idx:  \n",
    "            tree_dict[parent_idx]['children'].append(child_idx)\n",
    "            tree_dict[parent_idx]['hist_node']= Tr.get_parents(parent_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e063a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 6]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tr.get_parents(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "692b3672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'hypothesis': 'Fine-tune an ImageNet-pretrained WideResNet-28-10 on the 32×32 cactus dataset by (i) freezing all layers except the final block for the first 5 epochs, (ii) then unfreezing and training the entire network for 25 additional epochs with SGD (initial LR = 0.05, momentum = 0.9, weight-decay = 5e-4) under a cosine-annealing schedule, while applying CutOut (p = 1.0, size = 8) and CutMix (β = 1.0, p = 0.5) augmentations.',\n",
       "  'feedback': True,\n",
       "  'children': [2],\n",
       "  'hist_node': [0]},\n",
       " 1: {'hypothesis': 'Train a ResNet-18 variant whose stem is a single 3×3, stride-1 convolution (no max-pool) and that inserts a Squeeze-and-Excitation (SE) block after every residual block, optimising with AdamW (lr = 3e-4, weight_decay = 1e-4) for 25 epochs and validating with stratified 5-fold cross-validation; success is defined as mean CV ROC-AUC ≥ 0.995.',\n",
       "  'feedback': False,\n",
       "  'children': [6],\n",
       "  'hist_node': [1]},\n",
       " 2: {'hypothesis': 'Augment each training image with the pipeline: Rotate(limit = 45°, p = 1.0) → ColorJitter(brightness, contrast, saturation, hue = 0.2, p = 0.8) → RandomFog(fog_coef_lower = 0.1, fog_coef_upper = 0.25, alpha_coeffs=[0.08,0.12], p = 0.1) → RandomShadow(shadow_roi=(0,0,1,1), num_shadows_lower=1, num_shadows_upper=2, shadow_dimension=5, p = 0.2) → GaussianNoise(var_limit=(5,10), p = 0.15) → CoarseDropout(max_holes=1, max_height=8, max_width=8, fill_value=0, p = 1.0) → Normalize+ToTensor; retain CutMix in the collate_fn but reduce its probability to 0.3.',\n",
       "  'feedback': False,\n",
       "  'children': [4],\n",
       "  'hist_node': [0, 2]},\n",
       " 3: {'hypothesis': 'Replace BCE with the differentiable AUC-Margin loss (pairwise hinge, margin = 0.4) implemented via the torch-metrics ‘AUCMarginLoss’, keeping the existing data loader unchanged and training the baseline CNN for exactly the same 15 epochs to isolate the effect on validation ROC-AUC.',\n",
       "  'feedback': False,\n",
       "  'children': [9],\n",
       "  'hist_node': [3]},\n",
       " 4: {'hypothesis': 'Compute an 8×8 perceptual hash (imagehash.phash) for every image, cluster images whose hashes differ by ≤5 Hamming bits into the same group, then generate a single stratified 80/20 split with sklearn StratifiedGroupKFold (n_splits=5, random_state=2024) while preserving class balance; retrain the existing WideResNet-28-10 on this split and expect the validation ROC-AUC to drop by <0.002 if previous leakage was negligible, otherwise by >0.002.',\n",
       "  'feedback': True,\n",
       "  'children': [7],\n",
       "  'hist_node': [0, 2, 4]},\n",
       " 5: {'hypothesis': 'Resize every image to 64×64 with bicubic interpolation, set EfficientNet-B0’s first convolution stride to 1 (kernel 3×3, weights bilinearly interpolated from the ImageNet stem), and fine-tune the full network for 15 epochs using RandomResizedCrop(scale=0.8-1.0), RandAugment(N=2,M=9), and Cutout(size=8); evaluate by 5-fold stratified CV and expect ≥0.002 absolute ROC-AUC gain versus a baseline ResNet18 trained on the native 32×32 images.',\n",
       "  'feedback': True,\n",
       "  'children': [8],\n",
       "  'hist_node': [5]},\n",
       " 6: {'hypothesis': 'Replace the current backbone with a WideResNet-16-8 whose stem is a single 3×3 stride-1 conv (no pooling) and whose residual blocks all keep stride-1; include dropout p = 0.3 after each block, train with AdamW (lr = 2e-4, weight_decay = 1e-4) using 5-fold stratified CV for up to 20 epochs and stop early when mean CV ROC-AUC stops improving for 3 consecutive epochs.',\n",
       "  'feedback': True,\n",
       "  'children': [12],\n",
       "  'hist_node': [1, 6]},\n",
       " 7: {'hypothesis': 'Create five StratifiedGroupKFold splits (same deep-embedding groups as above), train one WRN28_10 per fold using 2 frozen + 18 unfrozen epochs with early-stopping (patience = 3) so that total wall-time stays < 60 min, and at inference average the five test-set logits before the final sigmoid; evaluate ensemble ROC-AUC on the private leaderboard.',\n",
       "  'feedback': False,\n",
       "  'children': [10],\n",
       "  'hist_node': [0, 2, 4, 7]},\n",
       " 8: {'hypothesis': 'Replace BCEWithLogitsLoss with a sigmoid-based focal loss (γ = 2.0, α = [0.75, 0.25]) across all three backbones and revert every DataLoader to plain random shuffling (no WeightedRandomSampler), then retrain each model under the same 5-fold CV and compare the mean CV ROC-AUC to the current baseline.',\n",
       "  'feedback': True,\n",
       "  'children': [11],\n",
       "  'hist_node': [5, 8]},\n",
       " 9: {'hypothesis': 'Implement an Albumentations train pipeline of horizontal/vertical flip (p=0.5), random brightness/contrast (p=0.3, limit ±0.15) and rotation ±10° (p=0.4); add Cutout covering ≤10 % area (p=0.3) and Mixup α = 0.1 applied after all spatial transforms; train the existing CNN 25 epochs with early-stop patience 4 using weighted BCE (class weights inverse-freq) and validate via 5-fold stratified ROC-AUC.',\n",
       "  'feedback': True,\n",
       "  'children': [13],\n",
       "  'hist_node': [3, 9]},\n",
       " 10: {'hypothesis': 'Insert a single 3×3 Conv layer (in_channels=3, out_channels=12, padding=1) followed by PixelShuffle(upscale_factor=2) and ReLU to create a learnable 2× super-resolution front-end that outputs a 3×64×64 tensor, freeze this SR block for the first 5 epochs, then jointly fine-tune it with WideResNet-28-10 for another 45 epochs using the existing training schedule; success is defined as ≥0.001 absolute gain in group-aware validation ROC-AUC over the current 0.999952 baseline.',\n",
       "  'feedback': False,\n",
       "  'children': [14],\n",
       "  'hist_node': [0, 2, 4, 7, 10]},\n",
       " 11: {'hypothesis': 'Extend the training transform for every backbone with ColourJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05) followed by RandomApply of an HSV shift ±10°, and at inference average logits over four test-time flips {none, h, v, h+v}; retrain under the same 5-fold CV and expect at least a 0.0005 absolute ROC-AUC gain on the ensemble.',\n",
       "  'feedback': False,\n",
       "  'children': [15],\n",
       "  'hist_node': [5, 8, 11]},\n",
       " 12: {'hypothesis': 'Compute an NDVI-style channel per image as (G−R)/(G+R+1e-6), concatenate it to RGB to form a 4-channel tensor, modify the WRN16-8 first convolution to in_channels=4 with the new channel weights initialised to the mean of the pretrained RGB filters, keep the existing flip+rotation augmentations, and declare success if single-fold ROC-AUC improves by ≥0.0003 compared with the RGB-only control.',\n",
       "  'feedback': True,\n",
       "  'children': [16],\n",
       "  'hist_node': [1, 6, 12]},\n",
       " 13: {'hypothesis': 'Replace BCEWithLogitsLoss(pos_weight) with class-balanced BCE where per-class weight w_c = (1 − β)/(1 − β^{n_c}) using β = 0.99 and n_c the class sample count, keeping mixup and disabling the WeightedRandomSampler so batches are shuffled normally.',\n",
       "  'feedback': True,\n",
       "  'children': [18],\n",
       "  'hist_node': [3, 9, 13]},\n",
       " 14: {'hypothesis': 'Replace AUCMLoss with BCEWithLogitsLoss(pos_weight = 0.333) and add a ROCStar regularisation term weighted by λ = 0.1, annealed linearly to 0 over the last 10 % of epochs; treat the change as successful if the group-aware validation ROC-AUC increases by at least 0.0005 without lengthening total training time.',\n",
       "  'feedback': False,\n",
       "  'children': [17],\n",
       "  'hist_node': [0, 2, 4, 7, 10, 14]},\n",
       " 15: {'hypothesis': 'Replace current training transforms with Compose([RandomRotation(±30°), RandomHorizontalFlip(0.5), RandomVerticalFlip(0.1), ColorJitter(0.15,0.15,0.15,0.03), Cutout(4)]) while retaining RandomResizedCrop, and at inference average logits over four views {original, h-flip, v-flip, rot90}; keep batch size 64 and all other settings fixed, then accept the change if ensemble OOF ROC-AUC increases by ≥0.0003.',\n",
       "  'feedback': False,\n",
       "  'children': [20],\n",
       "  'hist_node': [5, 8, 11, 15]},\n",
       " 16: {'hypothesis': 'Move RandomHorizontalFlipV4, Random90dRotation, and ColorJitter4ch into a standalone transforms4ch.py module so they are picklable, then set DataLoader(num_workers=4, persistent_workers=True, prefetch_factor=2) and verify that epoch time decreases by at least 40 % compared with num_workers=0.',\n",
       "  'feedback': False,\n",
       "  'children': [19],\n",
       "  'hist_node': [1, 6, 12, 16]},\n",
       " 17: {'hypothesis': 'After normal model inference, compute an 8×8 perceptual hash for every test image; when the Hamming distance to any training image hash is ≤5 AND all matched training images share the same label, set the final probability to 0.3 × model_prob + 0.7 × label (1.0 or 0.0), otherwise keep model_prob.',\n",
       "  'feedback': False,\n",
       "  'children': [21],\n",
       "  'hist_node': [0, 2, 4, 7, 10, 14, 17]},\n",
       " 18: {'hypothesis': \"Replace the current backbone with a WideResNet-28-10 created via timm.create_model('wrn28_10', pretrained=False, in_chans=3, num_classes=1); keep the 3×3 initial convolution, initialise with He normal weights, freeze the first two network blocks for the first 3 epochs, then unfreeze and fine-tune for the remaining 27 epochs under the existing augmentation, optimizer, and learning-rate schedule.\",\n",
       "  'feedback': False,\n",
       "  'children': [23],\n",
       "  'hist_node': [3, 9, 13, 18]},\n",
       " 19: {'hypothesis': 'Wrap the end-to-end training/inference section in a try\\u2006/\\u2006finally block that records time.time() at entry and exit and always prints exactly two lines—“debug_time: {elapsed:.4f}” and “estimated_time: {(elapsed*(full/part)*(20/epochs)):.4f}”—before sys.exit; add a pytest unit test that runs `python main.py DEBUG` and asserts those substrings appear in stdout.',\n",
       "  'feedback': True,\n",
       "  'children': [22],\n",
       "  'hist_node': [1, 6, 12, 16, 19]},\n",
       " 20: {'hypothesis': 'Introduce EfficientNet-B2 with first-layer stride set to 1 and input images up-scaled to 96×96 with bicubic interpolation, train it for 20 epochs (batch_size = 32, lr = 1e-3, cosine schedule) under the existing focal-loss setup, and add its predictions to the ensemble via the logistic-regression stacker while keeping the original B0 and ResNet models unchanged.',\n",
       "  'feedback': False,\n",
       "  'children': [24],\n",
       "  'hist_node': [5, 8, 11, 15, 20]},\n",
       " 21: {'hypothesis': 'Train with balanced FocalLoss(alpha = 0.25, gamma = 2) for the first 5 epochs, then switch to the current AUCMLoss for the remaining epochs while keeping all other hyper-parameters unchanged.',\n",
       "  'feedback': True,\n",
       "  'children': [25],\n",
       "  'hist_node': [0, 2, 4, 7, 10, 14, 17, 21]},\n",
       " 22: {'hypothesis': 'Augment each image with two computed channels—HSV-Saturation and (G-R)/(G+R+1e-6)—forming a 5-channel tensor, adapt ResNet18 conv1 to in_channels=5 with the new kernels initialised to zero, and freeze conv1 for the first two epochs to stabilise learning.',\n",
       "  'feedback': True,\n",
       "  'children': [27],\n",
       "  'hist_node': [1, 6, 12, 16, 19, 22]},\n",
       " 23: {'hypothesis': 'Perform a grid search over mixup α ∈ {0, 0.1, 0.2} and cutout_percent ∈ {0.10, 0.18, 0.25} (9 combinations) using 2-fold CV and 3 training epochs per trial in debug mode; retrain full 5-fold with the parameter pair that yields the highest average ROC-AUC.',\n",
       "  'feedback': False,\n",
       "  'children': [26],\n",
       "  'hist_node': [3, 9, 13, 18, 23]},\n",
       " 24: {'hypothesis': 'Replace RandAugment in the efficientnet_balanced training pipeline with AugMix(severity=2, width=3, alpha=1.0) applied with probability 0.5, leaving ResNet pipelines unchanged, and accept the modification if EfficientNet’s mean 5-fold CV ROC-AUC improves by ≥0.0004.',\n",
       "  'feedback': False,\n",
       "  'children': [29],\n",
       "  'hist_node': [5, 8, 11, 15, 20, 24]},\n",
       " 25: {'hypothesis': 'Implement the FastAUC loss (Yu 2022) using cumulative positive/negative sums and autograd; after the focal-loss warm-up, train with FastAUC for all remaining epochs while increasing the batch size from 256 to 512, leaving all other hyper-parameters unchanged.',\n",
       "  'feedback': False,\n",
       "  'children': [28],\n",
       "  'hist_node': [0, 2, 4, 7, 10, 14, 17, 21, 25]},\n",
       " 26: {'hypothesis': \"Add a MobileNetV3-Small (timm model_name='mobilenetv3_small_100') with first conv changed to 3×3, stride=1, no initial pooling, and train it for 30 epochs using knowledge-distillation: total loss = 0.5·BCEWithLogitsLoss + 0.5·KLDivLoss(T=2) against frozen ResNet18 teacher logits; include this model’s predictions in the current fold-averaged ensemble with weight proportional to its validation ROC-AUC.\",\n",
       "  'feedback': True,\n",
       "  'children': [30, 31],\n",
       "  'hist_node': [3, 9, 13, 18, 23, 26]},\n",
       " 27: {'hypothesis': 'At inference, average logits over eight deterministic views per image (rotations 0°, 90°, 180°, 270° with and without horizontal flip) for each fold model, then compute the final probability by sigmoid on the averaged logits.',\n",
       "  'feedback': True,\n",
       "  'children': [32],\n",
       "  'hist_node': [1, 6, 12, 16, 19, 22, 27]},\n",
       " 28: {'hypothesis': 'Wrap main() in try\\u2006/\\u2006finally to record start/end timestamps, use signal.alarm to cap model-scanning and hash-grouping blocks at 30 s each, and in debug mode always load cached results rather than recomputing to ensure the run completes within 0.17 h while still printing debug_time and estimated_time.',\n",
       "  'feedback': True,\n",
       "  'children': []},\n",
       " 29: {'hypothesis': 'Run an Optuna study with 5 trials on a single fold of EfficientNet-B0 for 5 epochs each, searching RandAugment num_ops ∈ {1,2,3}, magnitude ∈ [5,15] and Cutout size ∈ [4,10]; pick the best configuration by fold AUC and retrain the full 5-fold CV with that configuration, accepting if EfficientNet-B0’s OOF ROC-AUC increases by ≥0.0005.',\n",
       "  'feedback': False,\n",
       "  'children': []},\n",
       " 30: {'hypothesis': \"Set DataLoader num_workers = min(8, os.cpu_count()), pin_memory=True, persistent_workers=True, and add cfg['cache_images']=True that pre-loads all train and test JPEGs into a uint8 tensor list at start-up (skipped when cfg['debug']=True) with Dataset returning torch.from_numpy(cached[idx]).\",\n",
       "  'feedback': False,\n",
       "  'children': [33, 34],\n",
       "  'hist_node': [3, 9, 13, 18, 23, 26, 30]},\n",
       " 31: {'hypothesis': 'Skip teacher re-training per fold by loading a single ImageNet-pretrained ResNet18 (stem adapted to 3×3, stride-1) as a fixed teacher whose weights remain frozen; train only the student with KD from this shared teacher, thereby cutting training time by ≈50 % while maintaining ROC-AUC ≥ current SOTA.',\n",
       "  'feedback': False,\n",
       "  'children': []},\n",
       " 32: {'hypothesis': 'Train an EfficientNet-B0 modified for 5-channel input (conv1 3×3, stride = 1, no max-pool, extra channels initialised with RGB weight mean) for 40 epochs per fold under mixed-precision and OneCycleLR (max_lr = 3e-3) across the same 5 stratified folds; then form a weighted logistic-level ensemble of all EfficientNet and existing ResNet18-5ch models, using OOF ROC-AUC as weights.',\n",
       "  'feedback': True,\n",
       "  'children': []},\n",
       " 33: {'hypothesis': 'Re-define the KD loss for binary outputs by (i) concatenating a zero-logit to both teacher and student logits so softmax operates on two classes, or (ii) computing KLDiv between student and teacher sigmoid probabilities for both positive and negative classes; combine this corrected KD with BCE as before and expect higher student ROC-AUC and a stronger blended ensemble.',\n",
       "  'feedback': False,\n",
       "  'children': []},\n",
       " 34: {'hypothesis': 'Compute two extra per-pixel channels (HSV-Saturation and NDVI = (G−R)/(G+R+1e-6)) to form a 5-channel tensor and adapt the first conv layers of both teacher and student (weights for new channels zero-initialised); train as before and compare AUC.',\n",
       "  'feedback': False,\n",
       "  'children': []}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af96fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_reply_tree_dict(self) -> dict[int, dict]:\n",
    "        tree_dict: dict[int, dict] = {}\n",
    "        for idx, (experiment, feedback) in enumerate(self.hist):\n",
    "            tree_dict[idx] = {\n",
    "                'hypothesis': experiment.hypothesis,\n",
    "                'feedback': feedback.decision,\n",
    "                'children': []\n",
    "            }\n",
    "        for child_idx, parents in enumerate(self.dag_parent):\n",
    "            for parent_idx in parents:\n",
    "                if parent_idx != child_idx:  \n",
    "                    tree_dict[parent_idx]['children'].append(child_idx)\n",
    "        \n",
    "        return tree_dict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
