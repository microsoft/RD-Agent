{
  "DeepScaleR-Preview-Dataset": {
    "file_name": "DeepScaleR-Preview-Dataset/deepscaler.json",
    "formatting": "alpaca",
    "columns": {
      "problem": "instruction",
      "answer": "output"
    },
    "category": [
      "math"
    ],
    "description": "REASONING FITNESS: This dataset is primarily answer-only. The solution field is empty for about 82% of samples (32,924/40,315). Among non-empty solutions, the median length is ~373 tokens (max ~4,264; p99 ~1,208), which is generally too short for rich chain-of-thought training without augmentation. Consequently, the data is best suited for short-answer supervision (mapping problem→instruction, answer→output), not for training long-form reasoning. STRUCTURE: Each record includes problem (LaTeX-formatted), solution (often empty; when present, uses LaTeX and may end with boxed forms or multiple-choice letters), and answer (concise final value, consistently populated). Many problems are AIME/AMC style with numeric or short-form answers spanning algebra, number theory, geometry, and combinatorics, so response targets are brief. ACTIONABLE PREPROCESSING: If you need reasoning traces, filter to the non-empty solution subset (~18%) and consider COT rewrite/expansion to reach longer reasoning lengths. For consistency, append or replace the final line of solution with the canonical answer field to avoid cases where boxed text shows multiple-choice letters instead of the value. If adopting a think-tag format, wrap solution as <think>…</think> and then append the answer, or merge fields offline before training. Avoid using raw solution-only mapping due to the high empty rate.",
    "readme": "---\nlanguage:\n- en\nsize_categories:\n- 10K<n<100K\nlicense: mit\nconfigs:\n- config_name: default\n  data_files:\n  - split: train\n    path: data/train-*\n  splits:\n  - name: train\n    num_examples: 40315\n---\n\n# DeepScaleR Mathematical Reasoning Dataset\n\nDataset for DeepScaleR: Surpassing O1-Preview with a 1.5B Model by Scaling RL.\n\n> DeepScaleR-1.5B-Preview achieves **43.1% Pass@1 accuracy on AIME 2024**, representing a **15% improvement** over the base model (28.8%) and **surpassing OpenAI's O1-Preview performance** with just 1.5B parameters through distributed reinforcement learning.\n\n## Overview\n\nThe **DeepScaleR dataset** is a carefully curated collection of approximately **40,000 unique mathematics problem-answer pairs** designed for training mathematical reasoning models through reinforcement learning. This dataset covers a wide range of competition-level mathematics problems from high school to olympiad level, providing a robust foundation for scaling RL algorithms on reasoning tasks.\n\nDeepScaleR demonstrates that sophisticated mathematical reasoning can be achieved through strategic data curation combined with iterative context length scaling (8K→16K→24K) using Group Relative Policy Optimization (GRPO).\n\n\n### Data Sources\n\nOur training dataset consists of problems compiled from prestigious mathematics competitions and curated datasets:\n\n- **AIME** (American Invitational Mathematics Examination) problems (1984-2023)\n- **AMC** (American Mathematics Competition) problems (prior to 2023)\n- **Omni-MATH** dataset\n- **Still** dataset\n\n### Data Fields\n\nThe dataset contains three key fields:\n\n- `problem`: The mathematical problem statement, formatted with LaTeX notation\n- `solution`: Official solution to the problem, including LaTeX formatting and boxed final answers. If there is no solution, the `solution` field is an empty string\n- `answer`: The final mathematical result/answer, usually extracted from the solution\n\n### token statistics\nFor column `solution`, the token statistics is:\n{\n  \"empty_value_count\": 32924,\n  \"min\": 2,\n  \"max\": 4264,\n  \"p50\": 373,\n  \"p99\": 1208\n}\n\n\n## Example\n```json\n{\n  \"problem\": \"Let $a_n=6^{n}+8^{n}$. Determine the remainder upon dividing $a_{83}$ by $49$.\",\n  \"solution\": \"$6^{83} + 8^{83} = (6+8)(6^{82}-6^{81}8+\\\\ldots-8^{81}6+8^{82})$\\nBecause $7|(6+8)$, we only consider $6^{82}-6^{81}8+\\\\ldots-8^{81}6+8^{82} \\\\pmod{7}$\\n$6^{82}-6^{81}8+\\\\ldots-8^{81}6+8^{82} \\\\equiv (-1)^{82} - (-1)^{81}+ \\\\ldots - (-1)^1 + 1 = 83 \\\\equiv 6 \\\\pmod{7}$\\n$6^{83} + 8^{83} \\\\equiv 14 \\\\cdot 6 \\\\equiv \\\\boxed{035} \\\\pmod{49}$\",\n  \"answer\": \"35\"\n}\n```\n\n\n## License\n\nThis dataset is released under the MIT License.\n\n"
  }
}